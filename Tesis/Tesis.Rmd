---
title: "Tesis de Licenciatura"
author: "Paola Corrales"
date: ''
output:
  pdf_document:
    keep_tex: yes
    latex_engine: xelatex
    number_sections: yes
    toc: yes
    toc_depth: 4
  word_document:
    reference_docx: word-template.docx
    toc: yes
    toc_depth: '4'
classoption: oneside
documentclass: book
fontsize: 12pt
geometry: inner = 3cm, outer = 2cm, top = 2.5cm, bottom = 2.5cm
header-includes:
- \linespread{1.25}
- \usepackage{subfig}
- \usepackage{hyperref}
lang: es-AR
link-citation: yes
csl: Bibliografia/meteorologica.csl
subtitle: Desarrollo de una metodología de trabajo para caracterizar el ciclo diurno
  del viento en la capa límite atmosférica a partir de datos de radar meteorológico
  y su posterior uso para la validación de modelos.
bibliography:
- Bibliografia/papers.bib
- Bibliografia/packages.bib
---

```{r setup, include=FALSE, cache = FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      cache = TRUE,
                      warning = FALSE,
                      message = FALSE)

knitr::write_bib(c("base", "data.table", "ggplot2", "metR"), 
                 file = "Bibliografia/packages.bib")
# librerías
library(metR)
library(ggplot2)
library(ggforce)
library(ggrepel)
library(lubridate)
library(magrittr)
library(dplyr)
library(dtplyr)
library(viridis)
library(directlabels)
library(data.table)
library(patchwork)
library(ncdf4)
library(knitr)
library(kableExtra)
#source("geom_contourlabel.R")
source("helpfun.R")

# Variables útiles
map <- setDT(fortify(rnaturalearth::ne_states(country = c("Argentina")))) %>%
  .[, rango := rrange(long, lat)] %>% 
  .[, azimut := azimuth(long, lat)]

map2 <- setDT(fortify(rnaturalearth::ne_countries(country = c("Brazil", "Uruguay")))) %>%
  .[, rango := rrange(long, lat)] %>% 
  .[, azimut := azimuth(long, lat)]
map <- rbind(map, map2)
setnames(map, "long", "lon")

text.height <- (297 - 50)/25.4
text.width <- (210 - 50)/25.4

color_manual <- c("#231151", "#d3436e", "#feba80")

path <- "~/Radar/WRF/"

remove(map2)
```
\renewcommand{\listtablename}{Índice de tablas} 
\renewcommand{\tablename}{Tabla} 

\listoffigures
\newpage

\listoftables
\newpage

\section*{Agradecimientos}
\newpage

\section*{Resumen}
\newpage

# Introducción

La capa límite planetaria (CLP) corresponde a la porción de atmósfera que se encuentra directamente influenciada por la superficie y que responde a sus forzantes en una escala de tiempo de una hora o menos [@Stull1988]. Los procesos que ocurren dentro de esta capa son de suma importancia para entender y pronosticar la evolución de la atmósfera en distintas escalas espaciales y temporales. En particular estos procesos controlan el intercambio de energía entre la superficie y la atmósfera afectando, entre otras cosas, las condiciones para la ocurrencia de convección húmeda profunda y la intensidad de las circulaciones de mesoescala, que tienen un alto impacto sobre las actividades humanas.

En nuestra región existen estudios que buscan caracterizar los procesos que ocurren en la capa límite de forma tal de poder avanzar en su entendimiento y su dependencia por ejemplo con las propiedades de la superficie o el estado de la atmósfera [@Mazzeo1990; @Ulke2000; @Gassmann2001; @Acevedo2014; @Tonti2015].

Dado que la ocurrencia de turbulencia en la  capa límite planetaria se da en múltiples escalas espaciales y temporales, la representación de los procesos que ocurren dentro de ella es un desafío para los modelos numéricos. Actualmene los modelos de simulación regional y global no cuentan con la resolución necesaria para representar los procesos de la CLP de forma explícita, debiendo recurrir a una representación simplificada. De esta manera se simula numéricamente una parte del espectro turbulento, mientras que los procesos en la escala de subgrilla se resuelven a través de parametrizaciones con cierres de distinto orden, es decir, con diferentes niveles de aproximaciones. 

Existen diferentes alternativas para parametrizar los procesos de capa límite pero pueden clasificarse en dos grandes grupos. De acuerdo a @Stull1988, las parametrizaciones con clausura local determinan el valor de cualquier variable desconocida en cada punto a partir del valor o el gradiente de una variable conocida en el mismo punto; suponiendo que la turbulencia tiene un comportamiento análogo a la difusión molecular. Por otro lado las parametrizaciones con clausura no local asumen que la turbulencia está caracterizada por la superposición de torbellinos de distintas escalas que transportan las características del medio; y para lograr esto, el valor de la variable desconocida en un punto es aproximada a partir de una variable conocida en varios puntos en el espacio. 

La validación de las parametrizaciones de CLP en distintas situaciones sinópticas es un tema de gran interés debido a la necesidad de modelar los procesos de subgrilla presentes que afectan procesos en el resto de las escalas de variabilidad atmosférica [@Xie2012; @Banks2016]. 

A nivel regional, la representación de la capa límite en los modelos numéricos ha recibido mucha atención en las zonas oceánicas (particularmente en los océanos tropicales, @Wang2004). Sin embargo, existen pocos estudios acerca del desempeño de las parametrizaciones de capa límite en las regiones continentales [@Ulke2001; @Ruiz2010; @Berri2012; @Rizza2013].

Uno de los principales desafíos a la hora de estudiar los procesos que ocurren en la capa límite o para validar cómo los modelos representan dichos procesos, es la disponibilidad de observaciones. Las redes de radiosondeos que permiten obtener perfiles de viento, temperatura y humedad en la capa límite miden con frecuencias temporales de entre 12 y 24 horas (solo eventualmente cada 6 horas) lo que impide analizar la evolución de las características de la CLP a lo largo del día.

Sin embargo los radares Doppler permiten estimar la componente radial del viento en un radio horizontal de hasta 240 km y a partir de esa información permiten reconstruir perfiles verticales de viento utilizando la técnica Velocity Azimuth Display (VAD). 

En días en los que no existen ecos producidos por hidrometeoros, los radares pueden detectar la velocidad del viento dentro de la capa límite a partir de blancos como los insectos, de acuerdo a @Rennie2010 estos datos podrían ser utilizados si se elimina el efecto de los ecos de terreno y otras observaciones erróneas. Las observaciones de radar están disponibles con una frecuencia temporal de hasta 5 minutos permitiendo obtener perfiles de viento con una resoloción temporal mucho mayor. 

La calidad de estos perfiles ha sido comparada con los perfiles obtenidos a partir de radiosondeos, encontrándose en general que los datos obtenidos resultan adecuados para su uso en el estudio de los procesos de capa límite y en la verificación de modelos numéricos [@Bousquet2008; @Salonen2008] y en la generación de condiciones iniciales para pronósticos a muy corto plazo [@Rennie2011].

Uno de los aspectos importantes a tener en cuenta en el uso de radares para el estudio de los perfiles de viento, es la necesidad de aplicar un riguroso control de calidad a los datos  que permita solucionar diversos aspectos que pueden afectar la confiabilidad de los mismo. Entre los problemas más comunes se cuentan: contaminación por ecos de terreno, efecto de aliasing, y contaminación por blancos móviles. Estos aspectos deben ser abordados antes de poder utilizar los datos para estimar el perfil de velocidad [@Holleman2008; @Rennie2011] aplicando algoritmos de control de calidad [@Ruiz2015; @Rennie2011].

La disponibilidad de la información de radar Doppler en Argentina ofrece un gran recurso de información para estudiar las propiedades de la capa límite planetaria en nuestra región y para validar la calidad de los modelos numéricos a la hora de representar dichas propiedades.

El objetivo de esta Tesis de Licenciatura es desarrollar una metodología para el estudio de los procesos de capa límite a partir de los datos de radar y analizar el comportamiento de distintas parametrizaciones de CLP disponibles en el modelo Weather Research and Forecasting (WRF - @Skamarock2008) al representar algunos de los procesos presentes a lo largo del día. 

Se plantea como hipótesis que los datos de viento radial obtenidos de información de radar permiten estimar los perfiles verticales de viento con una frecuencia temporal de 10 minutos, en un espesor que abarca desde superficie y hasta 2000 m de altura, permitiendo realizar una caracterización de la evolución temporal de dichos perfiles dentro de la capa límite atmosférica. La estimación de esos perfiles permitirán además validar las parametrizaciones de la capa límite que utilizan los modelos numéricos con una mayor resolución temporal a la utilizada en trabajos previos.

Para alcanzar el objetivo se realizó el siguiente procedimiento: En primer lugar se determinaron las características necesarias para identificar posibles casos de estudio que permitan analizar los procesos de CLP asociados al ciclo diario. Luego se procesó los datos de radar para caso en estudio y se aplicaron los controles de calidad necesarios antes de realizar el cálculo del VAD desarrollado y validado como parte de este trabajo. Se analizó la consistencia de los resultados obtenidos y las características principales de la variación del viento a lo largo del día. Para las simulaciones numéricas con el modelo WRF se define un dominio y condiciones iniciales adecuadas para modelar un caso de estudio utilizando algunas parametrizaciones disponibles. Se comparan las simulaciones con las observaciones previamente obtenidas y se analizan algunas variables asociadas a la turbulencia. 

De esta manera, este trabajo permite desarrollar una metodología para el tratamiento de observaciones no convencionales, su aplicación al estudio de los procesos de CLP y al modelado numérico de los mismos.

# Metodología

En esta sección se describen los datos utilizados en el trabajo y las metodologías aplicadas al análisis.

## Región y casos de estudio

Este trabajo centra el análisis en la región de la ciudad de Paraná (provincia de Entre Ríos, Argentina) donde se encuentran el Radar Doppler del INTA (Instituto Nacional de Tecnología Agropecuaria) y una estación meteorológica de superficie perteneciente al SMN (Servicio Meteorológico Nacional) separados por aproximadamente 9 kilómetros de distancia.

```{r topografia, fig.cap="Topografía de la región en estudio en metros sobre el nivel del mar. El punto negro indica la ubicación del Radar INTA Paraná, el punto rojo indica la ubicación de la estación Paraná Aero. \\label{topografia}", fig.scap="Topografía de la región en estudio en metros sobre el nivel del mar.", fig.width=0.75*text.width, fig.align='center'}
topo <- GetTopography(298.96, 299.95, -31.44, -32.25, resolution = 1/60, file.dir = "seudocache") %>% 
  .[, lon := ConvertLongitude(lon, from = 360)]

ggplot(topo, aes(lon, lat)) + 
  geom_contour_fill(aes(z = h)) +
  #geom_contour(aes(z = h), color = "black") +
  scale_fill_gradient(high = "#ffffff", low = "#252525", 
                       name = "",
                       guide = guide_colorbar(title.position = "top", 
                                              title.hjust = 0.5)) +
  scale_x_continuous(name = "Longitud", limits = c(-61.04, -60.05), expand = c(0,0)) +
  scale_y_continuous(name = "Latitud", limits = c(-32.25, -31.44), expand = c(0,0)) +
  annotate(geom = "point", x = -60.537289, y = -31.848438, size = 2) +
  annotate(geom = "point", x = -60.483333, y = -31.783333, size = 2, color = "red") +
  coord_quickmap() + 
  theme_minimal() + theme(panel.ontop = T)
remove(topo)
```

La elevación de la región elegida muestra un mínimo de 5 metros sobre el nivel del mar en la cuenca del Río Paraná y un máximo de aproximadamente 110 metros sobre el nivel del mar sobre el margen sudeste de río donde ubica tanto la estación meteorológica como el radar (Figura \ref{topografia}). La región está dominada por la presencia del río y las regiones costeras donde predominan los campos de pastizales o pasto con excepción la ciudad de Paraná (al norte), la ciudad de Santa Fé (al noreste) y pequeños conglomerados de casas. 

### Criterios utilizados para la selección de los casos de estudio

Con el objetivo analizar los procesos que ocurren en la CLP a lo largo del día es necesario identificar aquellas condiciones atmosféricas que permitan el desarrollo de la capa límite y al mismo tiene donde los datos de radar sean confiables. Por lo tanto se buscaron cumplir los siguientes criterios:

* **Viento moderado.** En estas situaciones los datos de radar son más confiables y permiten el desarrollo de la capa límite estable nocturna [@Gassmann2001].
* **Cielos despejados.** Para garantizar el calentamiento desde la superficie y el desarrollo de una capa límite mezclada.
* **Verano.** Donde el calentamiento es más intenso.

Las características previas se buscaron a partir del análisis de los datos de la estación meteorológica de superficie Paraná Aero provistos por el SMN y de reflectividad (dBZ) del radar de Paraná para los meses de enero de 2016 y 2017. 

En el primer tipo de datos se analizó la velocidad de viento, la cobertura nubosa y la precipitación observada a cada hora. En el caso de los datos de radar se observó la presencia de ecos meteorológicos en las inmediaciones del radar (a una distancia menor a 150 km) en cada tiempo disponible (aproximadamente cada 10 minutos). Un caso de estudio posible será aquel que cumpla con las características mencionadas durante las 24 horas del día aunque es deseable que las condiciones se mantengan durante las 12 horas previas al día en estudio ya que las características de la capa estable nocturna puede ser influenciada por las características de la capa mezclada del día anterior.

### Descripción de los casos de estudio

A partir de análisis previamente descripto se identificaron 3 casos de estudio que se describen a continuación.

#### Caso 1: 14 de enero de 2016

El caso 1 abarca el periodo de las 00 UTC del 14 de enero a las 00 UTC del 15 de enero de 2016. A escala regional se observó un anticiclón ubicado sobre el océano Atlántico y al este Uruguay a las 00 UTC de 14 de enero. Este sistema está asociado a vientos del noreste sobre el dominio en estudio. En superficie se registraron vientos débiles (menores a 2 m/s) del este y sureste en las primeras horas del periodo. En la estación meteorológica se observó nubosidad alta en las primeras horas de tipo cirroestrato que por momentos cortos cubrió el cielo. No se observaron ecos meteorológicos en la región del radar. **Que tanto afecta la nubosidad alta?**

Posteriormente, a las 12 UTC el anticiclón se intensifica y comienza a moverse hacia el NE y en superficie se observan vientos predominantes del noreste de hasta 6.5 m/s. No se observa nubosidad y la temperatura en superficie alcanza los 32.4°C.

**Humedad relativa disminuye de 85% a 35% en el periodo, no me queda clara la causa y tampoco se que tan importante puede ser esto luego**

#### Caso 2:

#### Caso 3:

## Descripción de los datos de radar

El radar ubicado en Paraná (Provincia de Entre Ríos) emite energía electromagnética en la banda C (4 a 8 GHz) y es de doble polarización.
La estrategia de escaneo de la atmósfera está programada para que la antena de giros en sentido horizontal de 360º y cambie de elevación sucesivamente 12 veces. El ángulo vertical varía entre 0.5° y 15.1°. El rango del radar (distancia a la que llega la señal desde la ubicación del radar) puede ser de 120, 240 y 480 km con una resolución espacial de 1 $\mathrm{km^2}$ [@Saibene2014] de acuerdo a la estrategia de escaneo.

El escaneo completo se realiza cada 10 minutos, dando 144 volúmenes de datos
diarios registrando para las distintas variables como reflectividad (dBZ) y velocidad
radial ($V_r$).

En este trabajo se usaron datos de radar con un rango de 240 km y 12 ángulos de elevación para los periodos comprendidos por cada caso de estudios provistos por **XXXX INTA XXXX**

Cada volumen de dato correspondiente a un tiempo de escaneo completo fue convertido al formato CfRadial con el paquete Radx C++ desarrollado por Mike Dixon (NCAR - National Center for Atmospheric Research) **CITA** para el posterior procesamiento y análisis. 
En particular se utilizó la variable de reflectividad sin procesamiento para determinar la presencia o no de ecos meteorológicos en el dominio cercano al radar y la velocidad radial para la obtención de los perfiles de viento. 

## Tratamiento de aliasing

Un problema importante al momento de utilizar los datos de velocidad radial es la contaminación por aliasing ya que afecta significativamente la calidad de los perfiles de viento finales, de acuerdo a @Gao2004 un 3% de contaminación por aliasing puede generar un error cuadrático medio del 50% en el perfil de viento medio a partir de la técnica VAD. El aliasing es la superposición de la señal de radar y ocurre cuando la velocidad real supera a la velocidad de Nyquist ($V_N$). Este parámetro es intrínseco a las características del radar ya que depende de la frecuencia y estrategia de escaneo y en particular de la frecuencia de repetición del pulso o señal que emite.

En el caso del radar de Paraná con la estrategia de escaneo de 240km de rango, tiene una $V_N = 6.7 m/s$ por lo que cualquier velocidad mayor se verá afectada por el aliasing. Esto puede verse en la Figura \ref{aliasing}, las regiones con aliasing se son aquellas que donde el valor de la velocidad radial salta al extremo opuesto de la escala. 

Existen muchos algoritmos que buscan solucionar el problema del aliasing [por ejemplo @Haase2004; @Lim2010] con distinto grado de éxito. Una opción válida es el algoritmo de corrección de aliasing basado en regiones similares disponible en la librería PyART [@Helmus2016], este algoritmo busca regiones con velocidad radial similar y transforma el rango de la variable hasta que todas las regiones fueron corregidas de tal manera de obtener un campo continuo. El campo de velocidad radial sin aliasing obtenido utilizando este algoritmo se muestra en la Figura \ref{no-aliasing}. 

A partir de la exploración visual puede observarse que el algoritmo resuelve el problema de manera satisfactoria y por esta razón se utilizará para preprocesar todos los volúmenes de datos de radar.

```{r aliasing, fig.cap="Velocidad radial (m/s) observada a las 06 UTC por el radar de Paraná en la elevación $1.3^{\\circ}$ y $V_N = 6.7 m/s$. Notar las escalas diferentes.", fig.subcap=c("Con aliasing \\label{aliasing}", "Sin aliasing \\label{no-aliasing}"), out.extra=" ", fig.width=0.48*text.width}

radar <- nc_open("seudocache/cfrad.20160114_060005.000_to_20160114_060431.001_INTA_Parana_SUR.nc")
azimut <- ncvar_get(radar, 'azimuth')   
elevacion <- ncvar_get(radar, 'elevation') 
rango <- ncvar_get(radar, 'range')      
V <- ncvar_get(radar, 'V')            
Vda <- ncvar_get(radar, 'Vda')
Vda[Vda > 99999] <- NA
elev <- unique(elevacion)

dimnames(V) <- list(rango = rango, azimut = azimut)
radar <- setDT(melt(V, value.name = "V")) 
radar[, elevacion := elevacion, by = rango]
radar[, Vda := c(Vda)]

radar[elevacion == elev[3] & !is.na(V), ] %>%
  RepeatLon(., colname = "azimut") %>% 
  ggplot(aes(azimut, rango/1000)) + 
  geom_path(data = map[rango <= 300*1000], aes(group = group), color = "darkgray") +
  geom_point(aes(color = V, size = rango)) +
  scale_color_divergent() +
  scale_size_area(max_size = 0.1) +
  scale_x_continuous(name = NULL, labels = NULL, breaks = seq(0, 359, 90)) +
  scale_y_continuous(name = "Distancia al centro (Km)", breaks = c(40, 120, 180, 240), 
                     limits = c(0, 300), expand = c(0, 0)) + 
  guides(size = "none") +
  coord_polar() +
  theme_minimal() + theme(legend.position = "bottom")

radar[elevacion == elev[3] & !is.na(Vda), ] %>%
  RepeatLon(., colname = "azimut") %>% 
  ggplot(aes(azimut, rango/1000)) + 
  geom_path(data = map[rango <= 300*1000], aes(group = group), color = "darkgray") +
  geom_point(aes(color = Vda, size = rango)) +
  scale_color_divergent(name = expression(V[da])) +
  scale_size_area(max_size = 0.1) +
  scale_x_continuous(name = NULL, labels = NULL, breaks = seq(0, 359, 90)) +
  scale_y_continuous(name = "Distancia al centro (Km)", breaks = c(40, 120, 180, 240), 
                     limits = c(0, 300), expand = c(0, 0)) + 
  guides(size = "none") +
  coord_polar() +
  theme_minimal() + theme(legend.position = "bottom")
```

## Velocity Azimuth Display (VAD)

A medida que el radar rota en la dirección azimutal, mide la velocidad de los objetivos para cada ángulo y rango de manera continua y en función del azimut. A esto se le da el nombre de Visualización Azimutal de la Velocidad o por sus siglas en inglés VAD (por Velocity Azimuth Display, @Lhermitte1962) y se muestra en la Figura \ref{vad}. Si el campo de viento es horizontalmente homogéneo, la velocidad radial media tiene un comportamiento sinusoidal en función del azimut. 

```{r vad, fig.cap="Velocidad radial (m/s) en función del azimut (grados) para un rango y ańgulo de elevación fijos. En color se  ajusta una función sinusoidal a los datos. \\label{vad}", fig.width=0.75*text.width, fig.align='center'}
ggplot(radar[rango %~% 4000 & elevacion == elev[3], ], aes(azimut, Vda)) +
  geom_line() +
  geom_smooth(method = "lm", formula = y ~ I(sin(x*pi/180)) + I(cos(x*pi/180)), se = F, color = "#20968b") +
  scale_y_continuous(name = "Velocidad radial (m/s)") +
  scale_x_continuous(name = "Azimut (grados)") +
  geom_hline(yintercept = 0) +
  theme_minimal()

remove(list = c("radar", "V", "Vda", "azimut", "elev", "elevacion", "rango"))
```

De esta manera, la velocidad radial medida por el radar corresponde a la velocidad de un objetivo u obstáculo en el camino del haz. En situaciones de aire claro (sin nubosidad) es posible tener una medida del campo de viento dentro de la capa límite usando insectos como obstáculos. Sin embargo esta velocidad no corresponde al campo de movimiento real ya que es medida en la dirección radial siendo los valores negativos movimiento hacia el radar y valores positivos movimientos desde el radar. Mientras que el valor nulo ocurre en las regiones donde la velocidad real es perpendicular a la trayectoria del haz.

A partir de este concepto distintos autores han desarrollado técnicas para obtener el perfil vertical de viento real a partir del viento radial o su gradiente con diferentes grados de complejidad. Estas técnicas son también son llamadas VAD (o sus derivaciones, @Browning1968; @Matejka1991; @Gao2004a; @Xu2011).  Para esta tesis se desarrolló un algoritmo para el cálculo del VAD siguiendo a @Browning1968 pero incluyendo controles de calidad específicos para asegurar la validez de los resultados.

### Desarrollo matemático

El viento radial medido por el radar para un ángulo de elevación $\theta$ y rango $r$ determinado puede expresarse en función del azimut $\phi$:

\begin{equation}
\label{eq-vr1}
V_r =  v \cos(\theta) \cos(\phi) + u \cos(\theta) \sin(\phi) - w \sin(\theta)
\end{equation}

Donde $u$, $v$ y $w$ son las componentes del viento en coordenadas cartesianas.

La Ecuación \ref{eq-vr1} puede ser expresada como suma de una serie de Fourier de la forma:

\begin{equation}
\label{eq-vr2}
V_r =  \frac{1}{2}a_0 + \sum_{n = 1}^{\infty} (a_n \cos(n\phi) + b_n \sin(n \phi)) 
\end{equation}

Para $n=1$, los coeficientes de Fourier están asociados al viento en el centro del dominio de escaneo (con subíndice 0) como:

\begin{equation} \label{eq-vr3}
a_1 = u_0 \cos(\theta) \; y \;
b_1 = v_0 \cos(\theta) 
\end{equation}

A partir de esto es posible ajustar cada anillo de datos de radar, es decir los datos para cada $\theta$ y $r$ realizando una regresión lineal de la forma:

\begin{equation}
\label{eq-vr4}
V_r \sim a_1\cos \phi + b_1 \sin \phi
\end{equation}

Los coeficientes $a_0$, $a_2$ y $b_2$ no incluidos en el algoritmo dan información sobre la divergencia horizontal y otras características del viento, quedando su implementación para futuros trabajos.

Finalmente la velocidad y dirección del viento pueden ser calculadas a partir de los coeficientes (Ecuaciones \ref{eq-vr3}).

Velocidad:

\begin{equation}
\label{eq-vr5}
V = \frac{(a_{1}^{2} + b_{1}^{2})^{1/2}}{\cos(\theta)}
\end{equation}
  
Dirección:

\begin{equation}\label{eq-vr6}
\alpha = \frac{\pi}{2}-\tan^{-1}(\frac{a_1}{b_1}) \; \; si \; b_1 < 0 
\end{equation}
\begin{equation}\label{eq-vr7}
\alpha = \frac{3\pi}{2}-\tan^{-1}(\frac{a_1}{b_1}) \; \; si \; b_1 > 0
\end{equation}

El resultado de lo anterior un valor de la magnitud del viento y su dirección para cada anillo asociado a un ángulo de elevación y rango determinado. Para calcular la altura de cada anillo es necesario conocer la propagación del haz del radar. La propagación depende del indice de refracción de la atmósfera (N) y este a su vez de la densidad del aire y por lo tanto de las condiciones de temperatura y humedad del momento. Existen distintas metodologías para obtener calcular la propagación del haz del radar [@Zeng2014] que varían en su complejidad y precisión. 

En el algoritmo de VAD desarrollado se aplica el modelo 4/3 del radio de la Tierra. Este modelo es utilizado por la mayoría de los programas de procesamiento de datos de radar ya que pese a su simpleza (no toma en cuenta las condiciones de la atmósfera) es aceptable para cualquier ángulo de elevación usado, alturas máximas de entre 10 y 20 km siempre que el gradiente de N esté alrededor de $-1/a$ donde $a$ es el radio de la tierra [@Doviak1993].

Por otro lado se calcula la raíz del error cuadrático medio asociado a cada anillo ($rmse_a$) para estimar la diferencia entre las observaciones y el modelo estimado:

\begin{equation}\label{eq-vr8}
rmse_a = \sqrt {\sum \frac {(V_r - V_{rmod} )^2} {n-3}}
\end{equation}

donde $n$ es el número de observaciones presentes en un anillo particular.

Para obtener un único perfil vertical de viento se interpola un promedio pesado del valor de las variaciones de los anillos de cada capa de atmósfera a una grilla vertical equiespaciada preestablecida. 

El algoritmo identifica los datos de $V$ para cualquier rango y ángulo de elevación que se encuentran en $z \pm d/2$ donde $z$ es el punto de grilla y $d$ es la resolución espacial de la grilla vertical. Para obtener el valor promedio de de $V$ correspondiente a la altura $z$ calcula un promedio pesando la variable por el $rmse_a$ y la distancia de cada anillo al radar $r$. De esta manera los anillos con mayor error y más alejados a punto donde se está estimando la velocidad y dirección del viento tienen menor influencia en el resultado final.  

\begin{equation}\label{eq-vr9}
\bar{V} = \frac {\sum w_i V_i} {\sum w_i}
\end{equation}

Donde $w_i = \frac {1}{rmse_{ai} + r_i}$ y el subíndice $i$ cuenta la cantidad de datos para cada intervalo $z \pm d/2$. De manera análoga se calcula la dirección del viento para cada punto de grilla vertical.

Finalmente se calcula el error de estimación asociado a cada punto de dos maneras:

* **$rmse_1$**

\begin{equation}\label{eq-vr10} 
rmse_1 = \frac{\sigma}{\sqrt{n}}
\end{equation}

Donde $n$ es la cantidad de anillo en esa capa y  $\sigma^{2}= \frac{\sum (V_i - \bar{V})^2 /rmse_{ai}^2}{\sum 1/rmse_{ai}^2}$ con $\bar{V}$ el promedio pesado de la velocidad del viento para la capa.

Este error relativo da cuenta de la distancia entre el la velocidad promedio calculada para ese nivel y el valor de cada anillo pesada por el error del anillo. De esta manera si el $rmse_{ai}$ es grande la diferencia $(V_i - \bar{V})^2$ tiene menor peso en el error del nivel. Por otro lado el denominador suma la inversa de errores de todos los anillos y por lo tanto mayores errores individuales generan un $rmse_1$ mayor. Es importante notar que $V_i$ y $\bar{V}$ no están necesariamente a la misma altura ya que $\bar{V}$ es el promedio de muchos $V_i$ dentro de una capa. 

* **$rmse_2$**

\begin{equation}\label{eq-vr11}
rmse_2 = \sqrt{\frac{1}{\sum \frac{1}{rmse_{ai}^2}}}
\end{equation}

Este rmse no toma en cuenta la posible dispersión de los valores individuales de los anillos respecto del valor medio pero retiene el error cuadrático medio de cada anillo y calcula la raíz del error cuadrático medio del nivel como la suma de la inversa de los errores individuales. 

### Controles de calidad de los datos

El algoritmo de VAD desarrollado incluye algunos controles de calidad para evitar errores asociados a problemas intrínsecos a los datos de radar. 

#### Antes del ajusta de los datos 

Permiten determinar cuales son los anillos de datos válidos y eliminar posibles errores aleatorios.

* **Ángulos de elevación seleccionados:** La presencia de ecos de terreno pueden generar que los campos de velocidad radial para los primeros ángulos de elevación sean muy ruidosos y sin coherencia espacial. En el otro extremo, los ángulos superiores suelen tener pocos datos válidos (es decir, no dato faltante) debido a la escasa señal cerca del tope de la capa límite y atmósfera libre en días claros. Debido a esto es posible seleccionar el rango de ángulos a ser analizados y utilizados en el cálculo del VAD con el $Ángulo \; mínimo$ y el $Ángulo \; máximo$.
* **Selección del dominio de cálculo:** Otro posibilidad para evitar los ecos de terreno es definir un $Radio \; interior$ por debajo del cual no se incluyen los datos para el cálculo de VAD. En el otro extremo, es posible definir un $Radio \; exterior$ para limitar el uso de datos muy lejanos al centro del volumen de escaneo. Esto es importante para evitar inhomogeneidades en el campo de viento horizontal.
* **Cantidad de datos por anillo:** el algoritmo cuenta la cantidad de datos válidos por anillo y se define un porcentaje de datos faltantes respecto del total, por ejemplo 20%. Si se excede al máximo definido o $NaN \; máximo$ el anillo es descartado. De esta manera se evita la utilización de anillos donde la señal es muy débil.
* **Hueco continuo en un anillo:** Además de los datos faltantes ubicados de manera aleatoria a lo largo de un anillo, los huecos continuos pueden ocurrir debido a la falta de señal en una determinada región. De acuerdo a @Matejka1991 esto puede generar importantes errores en el resultado final, por lo tanto cuando el hueco o $Gap \; máximo$ es mayor a 30° de azimut, el anillo se descarta.
* **Errores aleatorios:** Los errores aleatorios producto de ruido del instrumento pueden ser eliminados utilizando un filtro pasa bajo [@Gao2004]. Este control no elimina anillos pero produce un suavizado de los datos. Es necesario definir la cantidad de datos o $Pesos$ que se utilizaran para calcular filtro en cada punto.

#### Luego del ajuste

* **R cuadrado:** El $r^2$ del modelo ajustado (Ecuación \ref{eq-vr4}) permite obtener una medida de
de la calidad de ese modelo respecto de las observaciones. A partir de la exploración de resultados preliminares se observó que la definición de un umbral mínimo para el $r^2$ permite descartar anillos que pese a no tener datos faltantes eran erróneos.

### Validación del algoritmo

Una manera posible de validar los resultados del VAD es comparando cualitativa o cuantitativamente el perfil vertical de viento generado con los datos de un radiosondeo en el mismo momento. Debido a la inexistencia de sondeos en la región de Paraná se exploró la posibilidad de utilizar datos del Radar INTA Anguil que se encuentra en la provincia de La Pampa y radiosondeos de la estación del SMN Santa Rosa Aero (87623). i bien el radar y la estación meteorológica no están en la misma ubicación, se encuentran a unos 30 km de distancia y por lo tanto la estación está dentro del dominio de escaneo del radar. Sin embargo se encontró que la señal de $V_r$ en días de cielo claro es muy pobre y por lo tanto no supera los controles de calidad impuestos en el algoritmo. 

Pero también es posible reconstruir un campo de velocidad radial sintética interpolando la velocidad medida por la radiosonda utilizando la grilla del radar utilizando la Ecuación \ref{eq-vr1}. En este proceso se asume que el campo de viento tridimensional varía linealmente. Este campo de velocidad radial sintética $V_{rs}$ puede ser re transformado a un perfil vertical de viento utilizando el VAD y comparado con el sondeo original.

Para este segundo método de validación se utilizaron un volumen de datos del Radar INTA Anguil del 05 de enero de 2016 a las 12 UTC y los datos del radiosondeo de la estación del SMN Santa Rosa Aero (87623) para la misma hora. 
Además, dado que el resultado de la interpolación del viento real da un campo homogéneo, sin errores o datos faltantes, se aplicaron distintas fuentes de errores para que la validación sea más realista. 

#### Pruebas

* **Sin datos faltantes ni errores (SE)**

Se obtiene el $V_r$ interpolado a la grilla del radar de Anguil (con una estrategia de escaneo hasta 120 km de radio y 8 ángulos de elevación) a partir del sondeo.
Como los datos de sondeo llegan hasta los 30 km de altura, hay información disponible para interpolar los datos de $V-r$ para todos los ángulos de elevación y para cualquier rango. Sin embargo esto nos da muchos más datos de los disponibles normalmente. Es de esperar que el VAD resultante sea muy similar al sondeo y inicial pero esta primera validación también permite verificar que la transformación de $V$ a $V_r$ es correcta. 

```{r validacion, fig.cap="Velocidad radial (m/s) observada a las 12 UTC por el radar de Anguil en la elevación $1.3^{\\circ}$ y la misma variable transformada a partir del sondeo de la estación Santa Rosa Aero para la misma hora \\label{validacion}", fig.subcap=c("Datos de radar \\label{radar}", "Sin errores \\label{se}", "Con errores \\label{ce}", "Con errores + NAs \\label{na}"), out.extra=" ", fig.width=0.48*text.width, fig.ncol = 2, fig.show="h"}

radar <- nc_open("seudocache/cfrad.20160105_120423.000_to_20160105_120716.001_INTA_Anguil_SUR.nc")
azimut <- ncvar_get(radar, 'azimuth')   
elevacion <- ncvar_get(radar, 'elevation') 
rango <- ncvar_get(radar, 'range')      
Vr <- ncvar_get(radar, 'V')   
elev <- unique(elevacion)

Vrs <- read.csv("seudocache/Vr_ref_se.csv", sep = ";")
Vrs[, 1] <- NULL
Vrs <- as.matrix(Vrs)

Vre <- read.csv("seudocache/Vr_ref_ce.csv", sep = ";")
Vre[, 1] <- NULL
Vre <- as.matrix(Vre)

Vrena <- read.csv("seudocache/Vr_ref_na_ce.csv", sep = ";")
Vrena[, 1] <- NULL
Vrena <- as.matrix(Vrena)

dimnames(Vr) <- list(rango = rango, azimut = azimut)
dimnames(Vrs) <- list(azimut = azimut, rango = rango)
dimnames(Vre) <- list(azimut = azimut, rango = rango)
dimnames(Vrena) <- list(azimut = azimut, rango = rango)

radar1 <- setDT(melt(Vr, value.name = "Vr")) 
radar1[, elevacion := elevacion, by = rango]
# radar1[, Vrs := c(Vrs)]

radar2 <- setDT(melt(Vrs, value.name = "Vr")) 
radar2[, elevacion := elevacion, by = rango]

radar3 <- setDT(melt(Vre, value.name = "Vr")) 
radar3[, elevacion := elevacion, by = rango]

radar4 <- setDT(melt(Vrena, value.name = "Vr")) 
radar4[, elevacion := elevacion, by = rango]

radar <- radar1[radar2, on  = c("rango", "azimut", "elevacion")]
setnames(radar, "i.Vr", "Vrs")
radar[Vrs < -999, Vrs := NA]

radar <- radar[radar3, on  = c("rango", "azimut", "elevacion")]
setnames(radar, "i.Vr", "Vre")
radar[Vre < -999, Vre := NA]

radar <- radar[radar4, on  = c("rango", "azimut", "elevacion")]
setnames(radar, "i.Vr", "Vrena")
radar[Vrena < -999, Vrena := NA]

radar[elevacion == elev[3] & !is.na(Vr), ] %>%
  RepeatLon(., colname = "azimut") %>% 
  ggplot(aes(azimut, rango/1000)) + 
  # geom_path(data = map[rango <= 300*1000], aes(group = group), 
  #           color = "darkgray") +
  geom_point(aes(color = Vr, size = rango)) +
  scale_color_divergent(name = expression(V[r]), limits = c(-20,20)) +
  scale_size_area(max_size = 0.1) +
  scale_x_continuous(name = NULL, labels = NULL, breaks = seq(0, 359, 90)) +
  scale_y_continuous(name = "Distancia al centro (Km)", 
                     breaks = c(10, 20, 30, 40), 
                     limits = c(0, 50), expand = c(0, 0)) + 
  guides(size = "none") +
  coord_polar() +
  theme_minimal() + theme(legend.position = "bottom")

radar[elevacion == elev[3] & !is.na(Vrs), ] %>%
  RepeatLon(., colname = "azimut") %>% 
  ggplot(aes(azimut, rango/1000)) + 
  # geom_path(data = map[rango <= 300*1000], aes(group = group), 
  #           color = "darkgray") +
  geom_point(aes(color = Vrs, size = rango)) +
  scale_color_divergent(name = expression(V[rs]), limits = c(-20,20)) +
  scale_size_area(max_size = 0.1) +
  scale_x_continuous(name = NULL, labels = NULL, breaks = seq(0, 359, 90)) +
  scale_y_continuous(name = "Distancia al centro (Km)",
                     breaks = c(10, 20, 30, 40), 
                     limits = c(0, 50), expand = c(0, 0)) + 
  guides(size = "none") +
  coord_polar() +
  theme_minimal() + theme(legend.position = "bottom")

radar[elevacion == elev[3] & !is.na(Vre), ] %>%
  RepeatLon(., colname = "azimut") %>% 
  ggplot(aes(azimut, rango/1000)) + 
  # geom_path(data = map[rango <= 300*1000], aes(group = group), 
  #           color = "darkgray") +
  geom_point(aes(color = Vre, size = rango)) +
  scale_color_divergent(name = expression(V[rs]), limits = c(-20,20)) +
  scale_size_area(max_size = 0.1) +
  scale_x_continuous(name = NULL, labels = NULL, breaks = seq(0, 359, 90)) +
  scale_y_continuous(name = "Distancia al centro (Km)",
                     breaks = c(10, 20, 30, 40), 
                     limits = c(0, 50), expand = c(0, 0)) + 
  guides(size = "none") +
  coord_polar() +
  theme_minimal() + theme(legend.position = "bottom")

radar[elevacion == elev[3] & !is.na(Vrena), ] %>%
  RepeatLon(., colname = "azimut") %>% 
  ggplot(aes(azimut, rango/1000)) + 
  # geom_path(data = map[rango <= 300*1000], aes(group = group), 
  #           color = "darkgray") +
  geom_point(aes(color = Vrena, size = rango)) +
  scale_color_divergent(name = expression(V[rs]), limits = c(-20,20)) +
  scale_size_area(max_size = 0.1) +
  scale_x_continuous(name = NULL, labels = NULL, breaks = seq(0, 359, 90)) +
  scale_y_continuous(name = "Distancia al centro (Km)",
                     breaks = c(10, 20, 30, 40), 
                     limits = c(0, 50), expand = c(0, 0)) + 
  guides(size = "none") +
  coord_polar() +
  theme_minimal() + theme(legend.position = "bottom")

remove(list = c("radar1", "radar2", "radar3", "radar4", 
                "Vr", "Vrs", "Vre", "Vrena"))
```

En la Figura \ref{validacion} se puede observar el campo de $V_r$ observado por el radar (izquierda) y el campo de $V_{rs}$ obtenidos a partir del sondeo. Cualitativamente se observa que tanto la magnitud como la dirección del viento son similares pero también que el $V_rs$ cubre totalmente el dominio mientras que la señal del $V_r$ se extingue a los 15 km de rango. Cuantitativamente la diferencia $V_r - V_{rs}$ es grande en puntos localizados pero la media absoluta es de `r round(mean(abs(radar$Vr-radar$Vrs), na.rm = T), 2)` m/s, un valor razonable teniendo en cuenta que las observaciones son realizadas por instrumentos distintos.

* **Con errores aleatorios (EA)**

Para realizar una validación más realista se agregaron errores aleatorios al campo de $V_{rs}$, esto además permite analizar la sensibilidad del algoritmo a este tipo de errores.

El nuevo campo perturbado será:

\begin{equation} \label{eq-vr12}
V_{rs}'  = V_{rs} + \alpha \varepsilon(0,1)
\end{equation}

Donde $\alpha$ es la amplitud del error y $\varepsilon$ es un número aleatorio con distribución normal, $\mu = 0$ y $\sigma= 1$.

En la Figura \ref{ce} se muestra el campo resultante utilizando $\alpha = 1 m/s$, rápidamente se ve la variabilidad impuesta y también la disminución en la coherencia horizontal aunque se mantiene aproximadamente el signo de la variable en las distintas regiones.

* **Con errores aleatorios y datos faltantes (EA+NA)**

Otro problema importante en los datos de radar es la ausencia de señal, esto se ve como datos faltantes (NAs). Para analizar el efecto de los datos faltantes se aplicó una máscara de NAs al campo de $V_{rs}'$ de tal manera que sean los mismo NAs presentes en el volumen de datos de radar utilizados (Figura \ref{na}). 

#### Perfiles obtenidos

En la Figura \ref{validacion-perfiles} se muestra el perfil del sondeo para los primeros 3 km de altura y los perfiles calculado con VAD a partir de los distintos campos sintéticos. En cuanto a la magnitud no se ven diferencias importantes y al observar el detalle de los primeros 1000 metros de altura, la diferencia es menor a 0.5 m/s en todos los casos. Tampoco se observó sensibilidad al aumento de la amplitud de error (no se muestra).

```{r validacion-perfiles, fig.cap="Viento medio (m/s) en función de la altura a partir del sondeo, y las distintas pruevas de validación a la izquierda y el detalle ampliado del máximo en niveles bajos \\label{validacion-perfiles}", out.extra=" ", fig.width=0.95*text.width, fig.show="h"}
vad <- read.csv("seudocache/Vr_se_2016-01-05T12:04:23Z-INTA_Anguil.csv", 
                sep = ";", dec = ".", na.strings = "-9999")
vade <- read.csv("seudocache/Vr_ce_2016-01-05T12:04:23Z-INTA_Anguil.csv", 
                sep = ";", dec = ".", na.strings = "-9999")
vadena <- read.csv("seudocache/Vr_ce_na_2016-01-05T12:04:23Z-INTA_Anguil.csv", 
                   sep = ";", dec = ".", na.strings = "-9999")

sondeo <- read.csv("seudocache/sondeo.csv", sep = " ")
sondeo$ht <- (sondeo$ht-191)/1000
sondeo$spd <- sondeo$spd*0.5144444
vad$sondeo_spd <- sondeo$spd[2:17]
setDT(vad)

vad[, spd_e := vade$spd] 
vad[, spd_ena := vadena$spd] 
vad[, .(ht, sondeo_spd, spd, spd_e, spd_ena)] %>% 
  melt(id.vars = "ht") %>% 
ggplot(aes(ht, value, color = variable)) +
  geom_line()+
  geom_point() +
  scale_color_viridis(discrete = T, name = "Perfil", 
                      labels = c("Sondeo", "SE", "EA", "EA+NA")) +
  scale_x_continuous(name = "Altura (Km)") +
  scale_y_continuous(name = "V (m/s)", breaks = seq(0, 11, by = 1)) +
  coord_flip() +
  facet_zoom(xy = ht < 1, zoom.size = 1) +
  theme_minimal() 
  
remove(list = c("sondeo","vade", "vadena"))
```

```{r validacion-errores}
tmp <- melt(vad[, c("sondeo_spd", "spd", "spd_e", "spd_ena", "ht")], 
            id.vars = "ht")
tmp <- tmp[, .(rms = rms(value, tmp[variable == "sondeo_spd", value]),
        rre = rre(value, tmp[variable == "sondeo_spd", value])),
    by = variable][-1, ] %>% 
  .[, Prueba := c("SE", "EA", "EA+NA")] %>% 
  .[, c(4, 2, 3)]

kable(tmp, digits = 4, caption = "Errores calculados para las distintas pruebas de validación. \\label{validacion-errores}")
```


Esto puede verificarse con el cálculo de distintos errores [@Gao2004]: la raíz del error cuadrático medio ($rms = \sqrt{ \frac{\sum (V-V_{ref})^2}{N} }$) y el error relativo al rms ($rre = \sqrt{ \frac{\sum (V-V_{ref})^2}{\sum (V_{ref})^2} }$) donde $V_{ref}$ corresponde a la variable de referencia, en este caso el sondeo. Los resultados se muestran en la Tabla \ref{validacion-errores} y como puede observarse no hay un aumento importante al incorporar errores aleatorios y disminuye al quitar datos en la prueba EA+NA ya que los errores calculados son sensibles a la cantidad total de datos.

El efecto más importante en las pruebas de validación corresponde a la presencia de NAs. La falta de datos en distintas regiones para rangos a partir de 10 a 15 km impide el cálculo del perfil por encima de 800 metros (con excepción de un punto a los 2000 metros de altura).

### Configuración del algoritmo

En la Tabla \ref{parametros} se detallan los valores utilizados en los distintos parámetros necesarios para el algorimo VAD que se mantuvieron para todos los casos de estudio.

```{r parametros}
param <- read.csv("seudocache/parametros.csv", sep = ";", header = T)
kable(param, format = "latex", booktabs = T, caption = "Parámetros utilizados en el cálculo del VAD y la construcción de la grilla vertical para todos los casos. \\label{parametros}") %>% 
  collapse_rows(1)
```


## Consistencia temporal de las observaciones

Ya que uno de los objetivos de esta tesis es estudiar la evolución del viento a lo largo del día, es importante asegurar cierta consistencia temporal en los datos. La inconsistencia temporal puede deberse a que cada volumen de datos no es medido de manera instantánea si no que demora algunos minutos. Si bien en periodos sin cambios sinópticos importantes no se espera variaciones bruscas del viento, es posible que variaciones menores a los 10 minutos (resolución temporal de los datos de radar) estén afectando la consistencia temporal.

Para solucionar este problema se aplicó un suavizado pesado localmente o LOWESS (locally weighted scatterplot smoothing, @Cleveland1979). LOWESS es un método de regresión no paramétrica y por lo tanto no es necesario asumir que los datos tienen algún tipo de distribución particular. Esto lo hace un método flexible al representar el comportamiento de los datos. Por otro lado la estimación para cada punto se realiza utilizando la información de datos vecinos. Para esto se especifica cuantos datos vecinos se utilizaran para estimar cada punto local como una fracción del total de datos. 

Aplicación de este método permite eliminar variaciones temporales bruscas entre sets de datos y mejorar la coherencia.

**Necesito mostrar como quedan los datos acá? No quiero spoilear los resultados**

## Procesos asociados a la CLP

El estudio de los procesos que ocurren en la CLP es un desafío cuando no se cuentan con datos de la turbulencia. En esta tesis se abordan procesos que pueden ser estudiados a partir de los perfiles de viento y las variables de superficie.

### Determinación del estado de la turbulencia

El número de Richarson puede ser utilizado como un estimador de la estabilidad dinámica [@Stull1988] y por lo tanto de la turbulencia presente. A partir de algunas suposiciones como la valides de la teoría K es posible escribir el número de Richarson en termino de gradientes:

\begin{equation} \label{eq-ri1}
R_i = \frac{\frac{g}{\overline{\theta_v}} \frac{\partial \overline{\theta_v}}{\partial z}}
{\left [ \left (\frac{\partial \overline{u}}{\partial z} \right )^2 + \left (\frac{\partial \overline{v}}{\partial z} \right )^2  \right]}
\end{equation}

El numerador de la Ecuación \ref{eq-ri1} da cuenta de los procesos boyantes que tienen a destruir la turbulencia en condiciones estables y a producirla en condiciones inestables. El  denominador corresponde a la producción mecánica o por cortante. De acuerdo a @Stull1988 la turbulencia puede mantenerse si $R_i < R_T$, ya que por encima de este umbral (en general $R_T = 1$), el flujo turbulento se vuelve laminar.

Debido a que la estimación de los gradientes suele ser difícil, estos suelen ser expresados en términos de observaciones discretas. Surge así el número de Richarson Bulk:

\begin{equation} \label{eq-ri2}
R_b = \frac{g \, \Delta \overline{\theta_v} \, \Delta z}{\overline{\theta_v} \, [(\Delta \overline{u}^2) + [(\Delta \overline{v}^2)]}
\end{equation}

Para obtener el $R_b$ en cada tiempo y su variación con la altura es necesario, entonces con el perfil vertical de temperatura virtual ($\theta_v$), y de la velocidad del viento. Debido a que solo se cuenta con el valor de la temperatura en superficie, se utilizó la siguiente aproximación válida para estimar el número de Richarson en el periodo estable: 

\begin{equation} \label{eq-ri3}
R_i \sim \frac{(g  \: (\theta_i - \theta_f)/z_{máx})}{(\overline{\theta} \: (u_{máx}/z_{máx})^2)}
\end{equation}

Donde $\theta_i$ corresponde al valor de la temperatura virtual en superficie en el momento de transición entre la capa mezclada y el comienzo de la capa estable nocturna, por lo tanto será la temperatura en el tope de la capa estable asumiendo que la capa residual no se modifica. El valor de $\theta_f$ será la temperatura en superficie observado. Por último $u_{máx}$ es el valor máximo de viento observado y $z_{máx}$, la altura a la que ocurre este máximo y que coincide con el tope de la capa estable (Ver Sección \ref{sec-pbh}).

### Altura de la capa límite \label{sec-pbh}

La altura de la capa límite se define como la altura a la cual las características de la superficie no afecta la atmósfera. Las estimaciones de esta variable son muy diversas en la literatura y también sus aplicaciones a los modelos numéricos. 

Por ejemplo la altura de la capa estable nocturna puede definirse como la altura a la cual la intensidad de la turbulencia es una fracción del valor en superficie mientras que la altura de la capa mezclada puede determinarse como la altura a la que se observa el menor transporte vertical de calor. 

Teniendo en cuenta los datos disponibles se determinará la altura de la capa estable nocturna como la altura a la que ocurre el máximo de viento. 

**Ver si resulta lo de usar dBZ o si se puede hacer algo con la altura de la capa mezclada**

### Descripción del LLJ

El Jet nocturno de capas cajas o LLJ (Low Level Jet) es un fenómeno de mesoescala caracterizado por por una corriente fuerte de viento con máximos de entre 10 y 20 m/s que se localiza en los primeros cientos de metros de altura [@Stull1988]. Su extensión vertical es poca pero horizontalmente puede extenderse por cientos de kilómetros. De acuerdo a @Vera2006 en la región de Paraná el LLJ es observado frecuentemente en la estación de verano entre las 00 y las 06 UTC.

Existen distintos criterios para identificar el LLJ, en algunos casos se determina un umbral mínimo para la velocidad del viento a partir del cual se considera la existencia del LLJ siempre que este ocurra por debajo de algún nivel determinado. En otros casos, se busca que el viento sea supergeostrófico. En este trabajo se utilizará el criterio de @Bonner1968 que identifica el LLJ cuando el máximo del viento es superior a 12 m/s y decrece al menos 6 m/s hasta el próximo mínimo o hasta el nivel de 3 km.

El LLJ puede producirse por distintos mecanismos entre los que se pueden nombrar la topografía, baroclinicidad asociada a pendientes del terreno, frentes y oscilaciones inerciales. En algunas situaciones, varios mecanismos pueden contribuir a la formación del LLJ de manera conjunta. 

De acuerdo a @Blackadar1957 luego del atardecer, cuando no hay producción de turbulencia se produce un desacople de la capa mezclada y el viento tiende a acelerarse ante la ausencia de la fricción hacia el equilibrio geostrófico. Sin embargo la fuerza de Coriolis genera una oscilación inercial del viento alrededor del viento geostrófico produciendo un LLJ supergeostrófico durante el periodo estable. 

Esta oscilación puede verse en la rotación del vector del viento a lo largo del tiempo. Para el hemisferio sur ésta rotación será en sentido antihorario. El periodo de la oscilación inercial es de $P = 2\pi/f$, con $f$ el parámetro de Coriolis. A la latitud de Paraná $P = `r abs(round(24000/sin(-31.8)/3600, 2))`$ horas y por lo tanto se espera que el máximo viento ocurra para cuando se alcanza la mitad del periodo desde el atardecer [@Kallistratova2012].

## WRF

En este trabajo se utilizó el modelo WRF versión 3.9.1 para la realización de simulaciones numéricas que permitan comparar algunas de las parametrizaciones de CLP disponibles: YSU (Yonsei University Scheme), MYJ(Mellor–Yamada–Janjic) y ACM2 (Asymmetric Convection Model 2). 

Las simulaciones se integraron en un dominio anidado en un sentido de dos niveles, el nivel superior con una resolución de 12 x 12 km y 105 x 105 puntos de grilla y el nivel inferior con una resolución de 4 x 4 km y 253 x 253 puntos de grilla, ambos centrados en la ubicación del radar de Paraná. Como se puede ver en la Figura \ref{dom-modelo} cubre todo el centro y norte del país. Se utilizaron datos geográficos con 10 minutos de resolución para el dominio superior y 2 minutos para el dominio inferior.

Ambos dominios tienen una grilla vertical de 42 niveles eta configurados de manera hipérbolo tangencial para que los primeros 15 niveles se ubiquen en los primeros kilómetros. La presión en el tope del modelo es de 100 hPa. De acuerdo a @Shin2012 se determinó que el nivel inferior se ubique en z = 40 metros para evitar errores en algunas variables de superficie asociadas a la CLP.

```{r dominio, fig.cap="Dominios utilizados. \\label{dominio}", fig.subcap=c("Dominio utilizado en el modelo con resolución de 12 km (dominio exterior) y 4 km (dominio interior. El punto representa la ubicación del radar. \\label{dom-modelo}", "Topografía sobre el nivel del terreno respecto de la ubicación del radar. El circulo negro corresponde al dominio de análisis, de 40km de radio y centrado en el radar. \\label{dom-radar}"), fig.width=0.48*text.width, fig.align='center', fig.sep = "\\hfill"}

hgt <- ReadNetCDF(paste(path, "caso1_YSU/hgt_YSU.nc", sep = "")) %>% 
  .[date == "2016-01-14 21:00:00 UTC" & lev == 0.05, ]

circle <- setDT(expand.grid(lon = seq(-61.04, -60.05, by = 0.001),
                            lat = seq(-32.25, -31.44, by = 0.001)))
circle <- circle[inside(lon, lat) == T, ]

ggplot(map, aes(lon, lat)) +
  geom_path(aes(group = group), color = "darkgray") +
  scale_x_continuous(limits = c(-71, -50), breaks = MakeBreaks(5), 
                     name = "Longitud", expand = c(0,0)) +
  scale_y_continuous(limits = c(-39.5, -24), 
                     name = "Latitud", expand = c(0,0)) +
  annotate(geom = "rect", xmin = -66.3349, xmax = -54.8394, 
           ymin = -36.5501, ymax = -27.0726, fill = NA, color = "black") +
  annotate(geom = "rect", xmin = -68.0717, xmax = -53.1528, 
           ymin = -37.9493, ymax = -25.679, fill = NA, color = "black") +
  annotate(geom = "point", x = -60.537289, y = -31.848438, size = 1) +
  coord_map() + 
  theme_minimal()


ggplot(hgt, aes(lon, lat)) + 
  geom_contour_fill(aes(z = hgt - 73)) +
  geom_polygon(fill = NA, color = "black", 
               data = circle[chull(lon, lat)]) +
  scale_fill_gradient(high = "#ffffff", low = "#252525",
                       name = "Altura sobre el\nnivel de radar", 
                       guide = guide_colorbar(title.position = "top", 
                                              title.hjust = 0.5)) +
  scale_x_continuous(name = "Longitud", limits = c(-61.04, -60.05), expand = c(0,0)) +
  scale_y_continuous(name = "Latitud", limits = c(-32.25, -31.44), expand = c(0,0)) +
  annotate(geom = "point", x = -60.537289, y = -31.848438, size = 2) +
  # geom_point(data = subset(distances, inside == "TRUE")) +
  # geom_circle(data = circle, aes(x0 = x0, y0 = y0, r = r), inherit.aes = F) +
  coord_quickmap() +
  theme_minimal() + theme(panel.ontop = T)

remove(circle, hgt)
```

Se realizaron simulaciones para el periodo comprendido en el Caso 1, es decir, entre las 0600 UTC del 13 de enero a las 0000 del 15 de enero de 2016 en todos los casos. Las primeras 6 horas de simulación corresponden al "spin up" del modelo y las siguientes 36 horas pueden ser analizables. Si bien el estudio se centra en comparar las observaciones del 14 de enero con las simulaciones, es importante tener en cuenta que la capa estable nocturna puede ser muy influenciada por la capa mezclada del día anterior, por esta razón la simulación empieza 12 horas antes.

Para las condiciones iniciales para las 0600 UTC del 13 de enero de 2016 se utilizó el Análisis Final (FNL) de National Centers for Environmental Prediction (NCEP) con resolución de 0.25° X 0.25° y las condiciones de borde fueron forzadas por los mismos datos cada 6 horas. 

Para los procesos físicos no asociados a la CLP se usaron las siguientes parametrizaciones: RRTMG (Rapid Radiative Transfer Model for GCMs, @Mlawer1997) para la radiación de onda larga, Dudhia [@Dudhia1989]  para la radiación de onda corta, WSM6 (WRF Single-Moment 6-Class Microphysics,  @Hong2006a) para los procesos microfísicos, el esquema Kain-Fritsch para los procesos de convección y el modelo Noah de superficie [@Tewari2004].

### Parametrizaciones de capa límite

Se presentan las características generales de cada parametrización analizada y el esquema de capa de superficie asociado a cada una (ya que cada parametrización de CLP tiene una determinada parametrización de capa de superficie y lamentablemente no se puede utilizar una en común).

* **YSU**

El esquema YSU [@Hong2006] es un esquema no local y como previamente se mencionó, determina el valor de una variable no conocida en un punto a partir de variables conocidas en distintos puntos. Está configurado con una clausura de primer orden y considera la mezcla no local debido a torbellinos grandes agregando un término de ajuste de gradiente al gradiente local a cada variable de pronóstico. El esquema usa la parametrización de capa de superficie MM5 Monin-Obukohv Similarity.

* **MYJ**

El esquema MYJ es un esquema local que usa una clausura de orden 1.5 y determina los coeficientes de difusión a partir del cálculo de la energía cinética de las perturbaciones pronosticada [@Janjic1994]. MYJ usa el esquema de capa de superficie Janjic Eta Monin–Obukhov.

* **ACM2**

Este esquema es similar a YSU en el sentido de que es no local y  tiene clausura de primer orden. Sin embargo considera un transporte no local hacia arriba y un transporte local hacia abajo "capa a capa" para las variables de pronóstico [@Pleim2007]. También utiliza el esquema de capa de superficie MM5 Monin-Obukohv Similarity.

### Procesamiento de los datos

Las simulaciones fueron post procesadas con el módulo ARWPost donde se eligió una resolución vertical de 100 metros en los primeros kilómetros de la atmósfera de tal manera que coincida con la grilla vertical de las observaciones de radar. El dominio inicial fue recortado para analizar el disco de 40 km de radio alrededor del radar como se muestra en la Figura \ref{dom-radar}.

El análisis del viento requiere un segundo procesamiento para transformar la variable a la grilla del radar y de esta manera obtener el perfil vertical de viento a partir del VAD y de esa manera, mejorar la comparación con las observaciones. Este procesamiento se realiza con **AGREGAR** a partir de las salidas no procesadas del modelo.

El análisis del resto de las variables pueden hacerse tomando el dato del punto más cercano al radar o a partir del promedio espacial en todo el dominio analizado. Se explorarán ambas posibilidades para determinar posibles diferencias y analizar la homogeneidad espacial de las variables.

### Tratamiento de variables asociadas a la CLP

Fue posible configurar el modelo para obtener algunas variables específicas de los esquemas de CLP como la altura de la capa límite estimada por cada parametrización ($h$), la Longitud de Monin-Obukohv ($L$), la velocidad de fricción ($u_*$) y el coeficiente de difusividad de calor ($K_h$). 

#### Cálculo de la altura de la CLP

Si bien cada parametrización estima la altura de la CLP, esta estimación es distinta en cada esquema. YSU calcula el número de Richarson Bulk desde superficie y determina $h$ como la altura a la cual  $R_b$ alcanza un valor cŕitico: cero para el régimen inestable y 0.25 para el regimen estable [@Hong2006]. ACM2 utiliza el mismo valor crítico del $R_b$ pero en los casos inestables el cálculo del número de Richarson se realiza para la capa de entremezcla entre la CLP y la atmósfera libre [@Pleim2007]. Por otro lado el esquema MYJ diagnostica la altura de la CLP como la altura a la cual la energía cinética turbulenta alcanza un valor prescripto en $0.1 m^2/s^2$ [@Janjic1994].

Esto hace que la comparación entre las distintas parametrizaciones no sea del todo válida. Por esta razón además de utilizar el valor de $h$ para cada parametrización, en el caso de la capa estable nocturna se estimará la altura de la capa a partir de la altura a la que ocurre el máximo de viento siguiendo la metodología utilizada para la observaciones (Sección \ref{sec-pbh}) y realizar una mejor comparación.

#### Coeficientes de difusividad turbulenta

Si bien se obtuvo el valor de $K_h$ para cada punto de grilla y cada tiempo, no fue posible obtener el coeficiente de difusividad de cantidad de movimiento ($K_m$) directamente desde el modelo por lo que se estimó a partir de la relación $K_m = K_h \: P_r$ donde $P_r$ es el número de Prandtl. Este último se determinó calculando los perfiles de los coeficientes de difusividad según @Ulke2000:

* **Condiciones estables ($h/L > 0$)**

\begin{equation} \label{k-1}
K_m(z) =  ku_{*o}h\left (\frac{z}{h} \right )\left(1-\frac{z}{h} \right)\left (1 + 6.9\frac{h}{L}\frac{z}{h} \right)^{-1}
\end{equation}

\begin{equation} \label{k-2}
K_h(z) =  ku_{*o}h\left (\frac{z}{h} \right )\left(1-\frac{z}{h} \right)\left (1 + 9.2\frac{h}{L}\frac{z}{h} \right)^{-1}
\end{equation}

* **Condiciones inestables ($h/L < 0$)**

\begin{equation} \label{k-3}
K_m(z) =  ku_{*o}h\left (\frac{z}{h} \right )\left(1-\frac{z}{h} \right)\left (1 - 22\frac{h}{L}\frac{z}{h} \right)^{1/4}
\end{equation}

\begin{equation} \label{k-4}
K_h(z) =  ku_{*o}h\left (\frac{z}{h} \right )\left(1-\frac{z}{h} \right)\left (1 - 13\frac{h}{L}\frac{z}{h} \right)^{1/2}
\end{equation}

Y a partir de esto se obtiene $P_r(z) = K_m/K_h$ para obtener el coeficiente de difusividad de cantidad de movimientos a partir de los datos del modelo.

```{r remove-metodologia}
remove("param", "radar", "tmp", "vad")
```


# Resultados

## Descripción de los casos de estudio

```{r leo-vad}

superficie <- setDT(read.sup("seudocache/superficie.csv"))
sup_vad <- convert.sup(superficie)

# Caso 1 - 14/01/2016
vad_20160114 <- read.vad("../../20160114_240/vda*")  
vad_20160114 <- rbind(subset(sup_vad, 
                             day(date_time) == 14), vad_20160114)
vad_20160114[, caso := "Caso 1"]

# Caso 2 - 21/01/2016
vad_20160121 <- read.vad("../../20160121_240/vda*")  
vad_20160121 <- rbind(subset(sup_vad, 
                             day(date_time) == 21), vad_20160121)
vad_20160121[, caso := "Caso 2"]

# Caso 3 - 23/01/2016
vad_20160123 <- read.vad("../../20160123_240/vda*")  
vad_20160123 <- rbind(subset(sup_vad, 
                             day(date_time) == 23), vad_20160123)
vad_20160123[, caso := "Caso 3"]

remove(sup_vad)
```

## Análisis de las observaciones de radar procesadas con VAD

### Magnitud y velocidad del viento

```{r campo-caso1, fig.cap="Magnitud y dirección del viento  correspondiente al Caso 1 (14/01/2016) observados por el radar y procesados con VAD. En el caso de la magnitud del viento se muestra además los errores calculados ($rmse_1$ y $rmse_2$) cuando superan los 0.5 m/s. \\label{campo-caso1}", fig.subcap=c("Magnitud del viento. \\label{caso1-spd}", "Dirección. \\label{caso1-dir}"), fig.width=0.95*text.width, fig.height=0.4*text.height, fig.ncol=1}
vad_20160114[ht > 0.02] %>% 
  ggplot(aes(date_time, ht)) + 
  geom_contour(aes(z = spd_smooth, color = ..level..), binwidth = 1) +
  scale_color_viridis(name = "Magnitud\ndel viento", direction = 1,
                      breaks = seq(0, 16, 2), limits = c(0, 16), 
                      guide = guide_colorbar(order = 1)) + 
  geom_point(data = subset(vad_20160114, rmse1 > 0.5), 
             aes(size = rmse1), 
             shape = 1, color = "grey25") +
  geom_point(data = subset(vad_20160114, rmse2 > 0.5),
             aes(size = rmse2), 
             shape = 4, color = "grey25") +
  scale_size(name = "Error", guide = guide_legend(order = 2)) +
  scale_x_datetime(name = "Tiempo (UTC)", date_breaks = "3 hour",
                   date_labels = "%H:%M", expand = c(0,0)) +
  scale_y_continuous(name = "Altura (km)", limits = c(0,2), 
                     expand = c(0,0)) +
  theme_minimal()

vad_20160114[minute(date_time) == 0 & !is.na(spd_smooth)] %>% 
  ggplot(aes(date_time, ht)) +
  geom_arrow(aes(mag = spd_smooth, angle = di, color = spd_smooth),
             scale = 0.007, start = -90, direction = -1) +
  # geom_point(data = subset(vad_20160114, rmse1 > 0.5), 
  #            aes(size = rmse1), 
  #            shape = 1, color = "grey25") +
  # geom_point(data = subset(vad_20160114, rmse2 > 0.5),
  #            aes(size = rmse2), 
  #            shape = 4, color = "grey25") +
  scale_color_viridis(name = "Velocidad\ndel viento", 
                      breaks = seq(0, 16, 2), limits = c(0, 16)) +
  scale_size_continuous(range = c(0, 5), guide = "none") +
  scale_y_continuous(name = "Altura (km)", limits = c(0,2)) + 
  scale_x_datetime(name = "Hora (UTC)", 
                   date_breaks = "3 hour", date_labels = "%H:%M") +
  theme_minimal() 
```

```{r opcion-simplificada, eval=FALSE, include=FALSE}
vad_20160114[minute(date_time) == 0 & !is.na(spd_smooth) & ht > 0.02] %>% 
  ggplot(aes(date_time, ht)) +
  geom_contour(aes(z = spd_smooth), binwidth = 1, color = "darkgrey") +
  geom_point(data = subset(vad_20160114, rmse1 > 0.5), 
             aes(size = rmse1), 
             shape = 1, color = "grey25") +
  geom_point(data = subset(vad_20160114, rmse2 > 0.5),
             aes(size = rmse2), 
             shape = 4, color = "grey25") +
  geom_arrow(aes(mag = spd_smooth, angle = di, color = spd_smooth),
             scale = 0.007, start = -90, direction = -1) +
  scale_size_continuous(range = c(0, 5), name = "Error") +
  scale_color_viridis(name = "Magnitud\ndel viento") +
  scale_y_continuous(name = "Altura (km)", limits = c(0,2)) + 
  scale_x_datetime(name = "Tiempo (UTC)", 
                   date_breaks = "3 hour", date_labels = "%H UTC", 
                   expand = c(0,0)) +
  theme_minimal() 
```

```{r campo-caso2, fig.cap="Magnitud y dirección del viento  correspondiente al Caso 2 (21/01/2016) observados por el radar y procesados con VAD. En el caso de la magnitud del viento se muestra además los errores calculados ($rmse_1$ y $rmse_2$) cuando superan los 0.5 m/s. \\label{campo-caso2}", fig.subcap=c("Magnitud del viento. \\label{caso2-spd}", "Dirección. \\label{caso2-dir}"), fig.width=0.95*text.width, fig.height=0.4*text.height, fig.ncol=1}
vad_20160121[ht > 0.02] %>% 
  ggplot(aes(date_time, ht)) + 
  geom_contour(aes(z = spd_smooth, color = ..level..), binwidth = 1) +
  scale_color_viridis(name = "Magnitud\ndel viento", direction = 1,
                      breaks = seq(0, 16, 2), limits = c(0, 16), 
                      guide = guide_colorbar(order = 1)) + 
  geom_point(data = subset(vad_20160121, rmse1 > 0.5), 
             aes(size = rmse1), 
             shape = 1, color = "grey25") +
  geom_point(data = subset(vad_20160121, rmse2 > 0.5),
             aes(size = rmse2), 
             shape = 4, color = "grey25") +
  scale_size(name = "Error", guide = guide_legend(order = 2)) +
  scale_x_datetime(name = "Tiempo (UTC)", date_breaks = "3 hour",
                   date_labels = "%H:%M", expand = c(0,0)) +
  scale_y_continuous(name = "Altura (km)", limits = c(0,2), 
                     expand = c(0,0)) +
  theme_minimal()

vad_20160121[minute(date_time) == 0 & !is.na(spd_smooth)] %>% 
  ggplot(aes(date_time, ht)) +
  geom_arrow(aes(mag = spd_smooth, angle = di, color = spd_smooth),
             scale = 0.007, start = -90, direction = -1) +
  # geom_point(data = subset(vad_20160121, rmse1 > 0.5), 
  #            aes(size = rmse1), 
  #            shape = 1, color = "grey25") +
  # geom_point(data = subset(vad_20160121, rmse2 > 0.5),
  #            aes(size = rmse2), 
  #            shape = 4, color = "grey25") +
  scale_color_viridis(name = "Velocidad\ndel viento", 
                      breaks = seq(0, 16, 2), limits = c(0, 16)) +
  scale_size_continuous(range = c(0, 5), guide = "none") +
  scale_y_continuous(name = "Altura (km)", limits = c(0,2)) + 
  scale_x_datetime(name = "Hora (UTC)", 
                   date_breaks = "3 hour", date_labels = "%H:%M") +
  theme_minimal() 
```

```{r campo-caso3, fig.cap="Magnitud y dirección del viento  correspondiente al Caso 3 (23/01/2016) observados por el radar y procesados con VAD. En el caso de la magnitud del viento se muestra además los errores calculados ($rmse_1$ y $rmse_2$) cuando superan los 0.5 m/s. \\label{campo-caso3}", fig.subcap=c("Magnitud del viento. \\label{caso3-spd}", "Dirección. \\label{caso3-dir}"), fig.width=0.95*text.width, fig.height=0.4*text.height, fig.ncol=1}
vad_20160123[ht > 0.02] %>% 
  ggplot(aes(date_time, ht)) + 
  geom_contour(aes(z = spd_smooth, color = ..level..), binwidth = 1) +
  scale_color_viridis(name = "Magnitud\ndel viento", direction = 1,
                      breaks = seq(0, 16, 2), limits = c(0, 16), 
                      guide = guide_colorbar(order = 1)) + 
  geom_point(data = subset(vad_20160123, rmse1 > 0.5), 
             aes(size = rmse1), 
             shape = 1, color = "grey25") +
  geom_point(data = subset(vad_20160123, rmse2 > 0.5),
             aes(size = rmse2), 
             shape = 4, color = "grey25") +
  scale_size(name = "Error", guide = guide_legend(order = 2)) +
  scale_x_datetime(name = "Tiempo (UTC)", date_breaks = "3 hour",
                   date_labels = "%H:%M", expand = c(0,0)) +
  scale_y_continuous(name = "Altura (km)", limits = c(0,2), 
                     expand = c(0,0)) +
  theme_minimal()

vad_20160123[minute(date_time) == 0 & !is.na(spd_smooth)] %>% 
  ggplot(aes(date_time, ht)) +
  geom_arrow(aes(mag = spd_smooth, angle = di, color = spd_smooth),
             scale = 0.007, start = -90, direction = -1) +
  # geom_point(data = subset(vad_20160123, rmse1 > 0.5), 
  #            aes(size = rmse1), 
  #            shape = 1, color = "grey25") +
  # geom_point(data = subset(vad_20160123, rmse2 > 0.5),
  #            aes(size = rmse2), 
  #            shape = 4, color = "grey25") +
  scale_color_viridis(name = "Velocidad\ndel viento", 
                      breaks = seq(0, 16, 2), limits = c(0, 16)) +
  scale_size_continuous(range = c(0, 5), guide = "none") +
  scale_y_continuous(name = "Altura (km)", limits = c(0,2)) + 
  scale_x_datetime(name = "Hora (UTC)", 
                   date_breaks = "3 hour", date_labels = "%H:%M") +
  theme_minimal() 
```

```{r perfiles, fig.cap="Perfil de viento observado por el radar a las 0600 y las 1700 UTC y el $rmse_2$ en cada punto (sombreado) para los tres casos. Las marcas en los ejes indican la magnitud del viento máxima y mínima y la altura a la que ocurren. Los valores en superficie fueron obtenidos a partir de los datos del la estación meteorógica Paraná Aero. \\label{perfiles-horarios}", fig.width=0.95*text.width, fig.align='center'}
gdata <- rbindlist(list(vad_20160114, vad_20160121, vad_20160123)) %>% 
  .[minute(date_time) == 00 & hour(date_time) %in% c(06, 17) & ht < 2 &
      !is.na(spd_smooth)] 
ggplot(gdata, aes(ht, spd_smooth, color = as.factor(hour(date_time)))) +
  geom_line() +
  geom_rug(data = gdata[minute(date_time) == 00 & hour(date_time) == 6][, maxspd := max(spd_smooth, na.rm = T), by = caso][spd_smooth == maxspd]) +
  geom_rug(data = gdata[minute(date_time) == 00 & hour(date_time) == 6 & ht > 0.5][, minspd := min(spd_smooth, na.rm = T), by = caso][spd_smooth == minspd]) +
  geom_ribbon(aes(ymin = spd_smooth - rmse2, ymax = spd_smooth + rmse2,
              fill = as.factor(hour(date_time))), 
              alpha = 0.5, color = NA) +
  coord_flip() +
  scale_color_manual(name="Hora UTC", values = color_manual) + 
  scale_fill_manual(name="Hora UTC", values = color_manual) +
  scale_y_continuous(name = "V (m/s)") + 
  scale_x_continuous(name = "Altura (Km)", breaks = seq(0, 2, 0.5),
                     limits = c(0, 2)) + 
  facet_wrap(~caso) + 
  theme_minimal()
```


### Características de la capa límite

```{r make-ri}
sup_20160114 <- superficie[day(fecha) == 14]
ri_20160114 <- create.ri(vad_20160114, sup_20160114$fecha, sup_20160114$temp, sup_20160114$presion_estacion, 27.7, 1002.6)
ri_20160114[, caso := "Caso 1"]

sup_20160121 <- superficie[day(fecha) == 21]
ri_20160121 <- create.ri(vad_20160121, sup_20160121$fecha, sup_20160121$temp, sup_20160121$presion_estacion, 35.7, 1001.8)
ri_20160121[, caso := "Caso 2"]

sup_20160123 <- superficie[day(fecha) == 23]
ri_20160123 <- create.ri(vad_20160123, sup_20160123$fecha, sup_20160123$temp, sup_20160123$presion_estacion, 34.2, 998.8)
ri_20160123[, caso := "Caso 3"]

ri_vad <- rbindlist(list(ri_20160114, ri_20160121, ri_20160123))
ri_vad[, hora := day(date_time)]

remove(sup_20160114, sup_20160121, sup_20160123, 
            ri_20160114, ri_20160121, ri_20160123)
```


```{r estable-vad, fig.cap="Series de tiempo de la altura de la capa límite, cortante vertical y el número de Richarsdon en la capa estable nocturna para todos los casos de estudio. En a) y b) se muestra solo el período donde se observa el LLJ, en c) el período en cada caso se encuentra sombreado. \\label{estable-vad}", fig.subcap=c("Altura de la capa estable \\label{h-vad}", "Cortante ($u_{máx}/z_{máx}$) \\label{cortante-vad}", "Número de Richardson \\label{ri}"), fig.ncol=1, fig.height=0.24*text.height}
ri_vad$hora <- ri_vad$date_time
day(ri_vad$hora) = 14
lim <- as.POSIXct(c(as_datetime("2016-01-14 00:00:00"), as_datetime("2016-01-14 12:00:00")))
   
ri_vad[hour(hora) %between% c(0, 12)] %>% 
  .[(caso == "Caso 1" & hora %between% c(as_datetime("2016-01-14 03:50:00"), as_datetime("2016-01-14 09:40:00"))) | 
    (caso == "Caso 2" & hora %between% c(as_datetime("2016-01-14 04:00:00"), as_datetime("2016-01-14 10:50:00"))) |
    (caso == "Caso 3" & hora %between% c(as_datetime("2016-01-14 02:00:00"), as_datetime("2016-01-14 09:30:00")))] %>% 
  ggplot(aes(hora, z_max)) +
  geom_line(aes(color = caso)) +
  scale_color_viridis(name = "Casos", discrete = T) +
  scale_y_continuous(name = "h (Km)") +
  scale_x_datetime(name = NULL, limits = lim) +
  coord_cartesian(ylim = c(0, 0.8)) + 
  theme_minimal()

ri_vad[hour(hora) %between% c(0, 12)] %>% 
  .[(caso == "Caso 1" & hora %between% c(as_datetime("2016-01-14 03:50:00"), as_datetime("2016-01-14 09:40:00"))) |
    (caso == "Caso 2" & hora %between% c(as_datetime("2016-01-14 04:00:00"), as_datetime("2016-01-14 10:50:00"))) |
    (caso == "Caso 3" & hora %between% c(as_datetime("2016-01-14 02:00:00"), as_datetime("2016-01-14 09:30:00")))] %>%
  ggplot(aes(hora, u_max/z_max)) +
  geom_line(aes(color = caso)) +
  scale_color_viridis(name = "Casos", discrete = T) +
  scale_y_continuous(name = expression(paste(u[máx]/z[max], " (1/s)"))) +
  scale_x_datetime(name = NULL, limits = lim) +
  theme_minimal()

ri_vad[hour(hora) %between% c(0, 12)] %>% 
  ggplot(aes(hora, ri)) +
  annotate(geom = "rect", 
           xmin = as_datetime("2016-01-14 03:50:00"),
           xmax = as_datetime("2016-01-14 09:40:00"), 
           ymin = -Inf, ymax = Inf, 
           color = "#440154",
           fill = "#440154", alpha = 0.1) +
  annotate(geom = "rect", xmin = as_datetime("2016-01-14 04:00:00"),
           xmax = as_datetime("2016-01-14 10:50:00"), 
           ymin = -Inf, ymax = Inf, 
           color = "#21908c",
           fill = "#21908c", alpha = 0.1) +
    annotate(geom = "rect", xmin = as_datetime("2016-01-14 02:00:00"),
           xmax = as_datetime("2016-01-14 09:30:00"), 
           ymin = -Inf, ymax = Inf, 
           color = "#fde725",
           fill = "#fde725", alpha = 0.1) +
  geom_point(aes(color = caso)) +
  scale_color_viridis(name = "Casos", discrete = T) +
  geom_hline(yintercept = 1, color = "darkgray") +
  scale_y_continuous(name = "Ri") +
  scale_x_datetime(name = "Hora UTC", limits = lim) +
  theme_minimal()
```



```{r hodografa-horaria, fig.cap="Variación del vector del viento en función de la altura entre 100 y 3000 metros, para cada caso de estudio observada por el radar a las 0600 UTC. El triángulo marca el nivel inferior y los círculos grandes se ubican cada 500 metros. \\label{hodografa-h}", fig.align='center', fig.width=0.75*text.width}

gdata <- rbind(vad_20160114, vad_20160121, vad_20160123) %>% 
  .[minute(date_time) == 00 & hour(date_time) %in% c(06) &
      !is.na(spd_smooth) & ht > 0.02 & ht <= 3] 
ggplot(gdata, aes(u, v,  color = caso)) +
  geom_hline(yintercept = 0, color = "darkgrey") +
  geom_vline(xintercept = 0, color = "darkgrey") +
  geom_point(data=subset(gdata, ht != 0.1), size = 1) +
  geom_point(aes(x = ifelse(ht %in% seq(0.1, 3.0, 0.5), u, NA)),
             size = 2) +
  geom_point(data=subset(gdata, ht == 0.1), shape = 17, size = 3) +
  geom_path() +
  scale_color_viridis(name="Casos", discrete = T) + 
  scale_x_continuous(name = "u (m/s)") + 
  scale_y_continuous(name = "v (m/s)") +
  coord_equal() +
  theme_minimal() 
```


#### Oscilación inercial


```{r hodografa-nivel, fig.cap="Variación del vector del viento en función del tiempo para tres niveles. Cada circulo representa un valor horario (con circulos más grandes cada 6 horas) y el cuadrado marca el primer tiempo (0000 UTC). \\label{hodografa-n}", fig.subcap=c("Datos observados en la estación meteorológica. \\label{hodo-nivel1}", "Datos observados por el radar. \\label{hodo-nivel2}"), fig.width=0.95*text.width, fig.ncol=1, fig.align='center', fig.height=0.25*text.height}

gdata <- rbind(vad_20160114, vad_20160121, vad_20160123)
gdata <- as.data.table(gdata) %>%
  .[, hora := hour(date_time)] %>% 
  .[ht %in% c(0.01) & !is.na(spd_smooth) & 
      minute(date_time) == 00 & hora < 18] 
ggplot(gdata, aes(u, v,  color = as.factor(ht))) +
  geom_hline(yintercept = 0, color = "darkgrey") +
  geom_vline(xintercept = 0, color = "darkgrey") +
  geom_point(aes(x = ifelse(hour(date_time) != 0, u, NA)), size = 1) +
  geom_point(aes(x = ifelse(hour(date_time) %in% c(0,6,12), u, NA)),
             size = 2) +
  geom_point(aes(x = ifelse(hour(date_time) == 0, u, NA)), shape = 15,
             size = 3) +
  geom_path() +
  geom_text_repel(aes(label = JumpBy(hora, 6, fill = NA)), 
                  data = gdata[ht != 1]) +
  scale_color_manual(name="Altura", values = c("#231151", "#d3436e", "#feba80")) + 
  scale_x_continuous(name = "u (m/s)") + 
  scale_y_continuous(name = "v (m/s)") +
  coord_equal() +
  facet_wrap(~caso) +
  theme_minimal() 

gdata <- as.data.table(rbind(vad_20160114, vad_20160121, vad_20160123)) %>%
  .[, hora := hour(date_time)] %>% 
  .[ht %in% c(0.3, 1) & !is.na(spd_smooth) & 
      minute(date_time) == 00 & hora <= 18] 
ggplot(gdata, aes(u, v,  color = as.factor(ht))) +
  geom_hline(yintercept = 0, color = "darkgrey") +
  geom_vline(xintercept = 0, color = "darkgrey") +
  geom_point(aes(x = ifelse(hour(date_time) != 0, u, NA)), size = 1) +
  geom_point(aes(x = ifelse(hour(date_time) %in% c(0,6,12), u, NA)),
             size = 2) +
  geom_point(aes(x = ifelse(hour(date_time) == 0, u, NA)), shape = 15,
             size = 3) +
  geom_path() +
  geom_text_repel(aes(label = JumpBy(hora, 6, fill = NA)), 
                  data = gdata[ht != 1]) +
  scale_color_manual(name="Altura", values = c("#d3436e", "#feba80")) + 
  scale_x_continuous(name = "u (m/s)") + 
  scale_y_continuous(name = "v (m/s)") +
  coord_equal() +
  facet_wrap(~caso) +
  theme_minimal()

remove(gdata, vad_20160121, vad_20160123)
```

##Analisis de las simulaciones y comparación con observaciones de radar

### Magnitud y dirección del viento

```{r read-WRF-VAD}
# YSU
vad_caso1ysu <- read.vad("../../caso1ysu_240/vda*")
vad_caso1ysu[, caso := "YSU"]

#MYJ
vad_caso1myj <- read.vad("../../caso1myj_240/vda*")
vad_caso1myj[, caso := "MYJ"]

#ACM2
vad_caso1acm <- read.vad("../../caso1acm_240/vda*")
vad_caso1acm[, caso := "ACM2"]


vad_20160114 <- vad_20160114[, caso := "Obs"]
```


```{r vad-modelo-spd, fig.cap="Magnitud del viento observada por el radar (Obs) y simulada por el modelo WRF utilizando distintos esquemas de CLP para el Caso 1 (14/01/2016) y posteriormente procesados con VAD. \\label{modelo-spd}", fig.width=0.95*text.width, fig.align='center'}

gdata <- setDT(rbind(vad_20160114, vad_caso1ysu, vad_caso1myj, vad_caso1acm))
gdata[, caso2 := factor(caso,
                       levels = c("Obs", "YSU", "MYJ", "ACM2"),
                       ordered = T)]
gdata[ht > 0.02 & date_time %between% c(as_datetime("2016-01-14 00:00:00"), as_datetime("2016-01-15 00:00:00")) ] %>% 
  ggplot(aes(date_time, ht)) + 
  geom_contour(aes(z = spd_smooth, color = ..level..), binwidth = 1) +
  scale_color_viridis(name = "Magnitud\ndel viento", direction = 1,
                      breaks = seq(0, 18, 2), limits = c(0, 19),
                      guide = guide_colorbar(order = 1)) + 
  # geom_point(data = subset(gdata, rmse1 > 0.5),
  #            aes(size = rmse1),
  #            shape = 1, color = "grey25") +
  # geom_point(data = subset(gdata, rmse2 > 0.5),
  #            aes(size = rmse2),
  #            shape = 4, color = "grey25") +
  # scale_size(name = "Error", guide = guide_legend(order = 2)) +
  scale_x_datetime(name = "Hora (UTC)", date_breaks = "4 hour",
                   date_labels = "%H:%M", expand = c(0,0)) +
  scale_y_continuous(name = "Altura (km)", limits = c(0,2), 
                     expand = c(0,0)) +
  facet_wrap(~caso2) +
  theme_minimal()

```

```{r vad-modelo-dir, fig.cap="Dirección del viento observada por el radar(Obs) y simulada por el modelo WRF utilizando distintos esquemas de CLP para el Caso 1 (14/01/2016) y posteriormente procesados con VAD. \\label{modelo-dir}", fig.width=0.95*text.width, fig.align='center'}

gdata <- setDT(rbind(vad_20160114, vad_caso1ysu, vad_caso1myj, vad_caso1acm))
gdata[, caso2 := factor(caso,
                       levels = c("Obs", "YSU", "MYJ", "ACM2"),
                       ordered = T)]
gdata[ht > 0.02 & date_time %between% c(as_datetime("2016-01-14 00:00:00"), as_datetime("2016-01-15 00:00:00")) & minute(date_time) == 0 & !is.na(spd_smooth) ] %>% 
  ggplot(aes(date_time, ht)) +
  geom_arrow(aes(mag = spd_smooth, angle = di, color = spd_smooth),
             scale = 0.005, start = -90, direction = -1) +
  # geom_point(data = subset(vad_20160114, rmse1 > 0.5), 
  #            aes(size = rmse1), 
  #            shape = 1, color = "grey25") +
  # geom_point(data = subset(vad_20160114, rmse2 > 0.5),
  #            aes(size = rmse2), 
  #            shape = 4, color = "grey25") +
  scale_color_viridis(name = "Velocidad\ndel viento", 
                      breaks = seq(0, 18, 2), limits = c(0, 19)) +
  scale_size_continuous(range = c(0, 5), guide = "none") +
  scale_y_continuous(name = "Altura (km)", limits = c(0,2)) + 
  scale_x_datetime(name = "Hora (UTC)", 
                   date_breaks = "4 hour", date_labels = "%H:%M") +
  facet_wrap(~caso2) +
  theme_minimal() 

```


```{r diferencia, fig.cap="Diferencia entre las observaciones y cada simulación  correspondiente al Caso 1. \\label{dif}", fig.subcap=c("Magnitud del viento \\label{dif-spd}", "Dirección del viento \\label{dif-dir}"), fig.width=0.48*text.width, fig.height=0.70*text.height, fig.ncol=2}

gdata <- setDT(rbind(vad_caso1ysu, vad_caso1myj, vad_caso1acm))

gdata <- gdata[vad_20160114[, .(date_time, ht, spd_obs = spd_smooth, u_obs = u, v_obs = v)], 
      on = c("date_time", "ht")] %>% 
  .[, dif_spd := spd_obs - spd_smooth] %>% 
  .[, dif_u := u_obs - u] %>%
  .[, dif_v := v_obs - v] %>% 
  .[, dif_di := atan2(u, v)*180/pi] %>% 
  .[, caso2 := factor(caso,
                       levels = c("Obs", "YSU", "MYJ", "ACM2"),
                       ordered = T)]

gdata[ht > 0.02] %>% 
  ggplot(aes(date_time, ht)) + 
  geom_contour(aes(z = dif_spd, color = ..level..), binwidth = 1) +
  scale_color_divergent(name = "Magnitud\ndel viento", 
                      #breaks = seq(0, 18, 2), limits = c(0, 19),
                      guide = guide_colorbar(order = 1)) + 
  # geom_point(data = subset(gdata, rmse1 > 0.5),
  #            aes(size = rmse1),
  #            shape = 1, color = "grey25") +
  # geom_point(data = subset(gdata, rmse2 > 0.5),
  #            aes(size = rmse2),
  #            shape = 4, color = "grey25") +
  # scale_size(name = "Error", guide = guide_legend(order = 2)) +
  scale_x_datetime(name = "Tiempo (UTC)", date_breaks = "3 hour",
                   date_labels = "%H:%M", expand = c(0,0)) +
  scale_y_continuous(name = "Altura (km)", limits = c(0,2), 
                     expand = c(0,0)) +
  facet_wrap(~caso2, ncol = 1) +
  theme_minimal()

gdata[ht > 0.02 & caso2 != "Obs" & hour(date_time) < 22] %>% 
  ggplot(aes(date_time, ht)) + 
  # geom_tile(aes(z = dif_di, fill = dif_di), binwidth = 1) +
  # scale_fill_divergent(name = "Dirección\ndel viento", 
  #                     #breaks = seq(0, 18, 2), limits = c(0, 19),
  #                     guide = guide_colorbar(order = 1)) + 
  # geom_point(data = subset(gdata, rmse1 > 0.5),
  #            aes(size = rmse1),
  #            shape = 1, color = "grey25") +
  # geom_point(data = subset(gdata, rmse2 > 0.5),
  #            aes(size = rmse2),
  #            shape = 4, color = "grey25") +
  # scale_size(name = "Error", guide = guide_legend(order = 2)) +
  geom_arrow(aes(mag = dif_spd, angle = dif_di, color = dif_di),
             scale = 0.01, start = -90, direction = -1) +
  scale_color_divergent(name = "Dirección\ndel viento") +
  scale_x_datetime(name = "Tiempo (UTC)", date_breaks = "3 hour",
                   date_labels = "%H:%M", expand = c(0,0)) +
  scale_y_continuous(name = "Altura (km)", limits = c(0,2), 
                     expand = c(0,0)) +
  facet_wrap(~caso2, ncol = 1) +
  theme_minimal()
```


### Estructura de la capa límite

#### Oscilacion inercial y LLJ

```{r perfiles-mod, fig.cap="Perfil de viento observado por el radar a las 0600 y las 1700 UTC y perfiles simulados por el modelo para los mismos momentos. Las marcas en los ejes indican la magnitud del viento máxima y mínima y la altura a la que ocurren. \\label{perfiles-modelo}", fig.width=0.95*text.width, fig.align='center'}
gdata <- setDT(rbind(vad_20160114, vad_caso1ysu, vad_caso1myj, vad_caso1acm))
gdata[, caso2 := factor(caso,
                       levels = c("Obs", "YSU", "MYJ", "ACM2"),
                       ordered = T)] %>% 
  .[, hora := hour(date_time)] %>% 
  .[minute(date_time) == 00 & hour(date_time) %in% c(06, 17) & ht < 2 &
      !is.na(spd_smooth)] %>% 
  ggplot(aes(ht, spd_smooth, color = caso2)) +
  geom_line() +
  geom_rug(data = gdata[minute(date_time) == 00 & hour(date_time) == 6][, maxspd := max(spd_smooth, na.rm = T), by = caso2][spd_smooth == maxspd]) +
  geom_rug(data = gdata[minute(date_time) == 00 & hour(date_time) == 6 & ht > 0.5][, minspd := min(spd_smooth, na.rm = T), by = caso2][spd_smooth == minspd]) +
  # geom_ribbon(aes(ymin = spd_smooth - rmse2, ymax = spd_smooth + rmse2,
  #             fill = as.factor(hour(date_time))), 
  #             alpha = 0.5, color = NA) +
  coord_flip() +
  scale_color_manual(name= NULL, values = c("black", color_manual)) +
  scale_y_continuous(name = "V (m/s)") + 
  scale_x_continuous(name = "Altura (Km)", breaks = seq(0, 2, 0.5),
                     limits = c(0, 2)) + 
  facet_wrap(~hora, labeller = labeller(hora = c("6" = "06 UTC", "17" = "17 UTC"))) + 
  theme_minimal()
```

```{r hodografa-wrf, fig.cap="Variación del vector del viento en función del tiempo para tres niveles. Cada circulo representa un valor horario (con circulos más grandes cada 4 horas) y el cuadrado marca el primer tiempo (0000 UTC). \\label{hodografa-wrf}", fig.width=0.95*text.width, fig.align='center'}

gdata <- rbind(vad_20160114, vad_caso1ysu, vad_caso1myj, vad_caso1acm)
gdata <- as.data.table(gdata) %>%
  .[, hora := hour(date_time)] %>% 
  .[minute(date_time) == 00 & hora < 18] %>% 
  .[, caso2 := factor(caso,
                       levels = c("Obs", "YSU", "MYJ", "ACM2"),
                       ordered = T)] 

gdata[ht %in% c(0.3, 0.5, 1.0) & !is.na(spd_smooth)] %>% 
  ggplot(aes(u, v,  color = caso2)) +
  geom_hline(yintercept = 0, color = "darkgrey") +
  geom_vline(xintercept = 0, color = "darkgrey") +
  geom_point(aes(x = ifelse(hour(date_time) != 0, u, NA)), size = 1) +
  geom_point(aes(x = ifelse(hour(date_time) %in% c(0,4,8,12,16), u, NA)),
             size = 2) +
  geom_point(aes(x = ifelse(hour(date_time) == 0, u, NA)), shape = 15,
             size = 3) +
  geom_path() +
  # geom_text_repel(aes(label = JumpBy(hora, 6, fill = NA)), 
  #                  data = gdata[ht %in% c(0.3, 0.5, 1.0)]) +
  scale_color_manual(name="Altura", values = c("black", viridis_pal()(3))) + 
  scale_x_continuous(name = "u (m/s)") + 
  scale_y_continuous(name = "v (m/s)") +
  coord_equal() +
  facet_wrap(~ht) +
  theme_minimal() 

```

#### Análisis de la homogeneidad espacial en las variables de estabilidad

Para determinar la validez del promedio espacial de cada variable en el dominio en estudio es importante analizar la variabilidad de la misma espacial y temporalmente.

En el caso de la Longitud de Monin-Obukhov ($L$) se analizó el procentaje de veces que el valor local tenía signo distinto a la moda calculada para todo el dominio y cada tiempo de simulación. Esto es importante ya que el signo de $L$ marca la diferencia entre el regimen estable y el regimen inestable y por lo tanto debe mantenerse en el dominio. 

En la Figura \ref{L-espacial} se muestra el porcentaje de veces que el valor de L en cada punto de grilla tiene signo distinto a la moda calculada en todo el dominio y el período analizado. Se observa que que existen regiones donde el signo de $L$ es dsitnto a la moda del dominio más del 40% de las veces. Esto puede estar relacionado la variación de la altura del terreno (Figura \ref{topografia}) o a la presencia del río y zonas con suelos saturados donde los flujos verticales de calor ($F_{\theta}$) pueden tener un comportamiento contrario al suelo seco. Esto último se observa en la Figura \ref{L-espacial}, donde se muestra que las regiones donde el porcentaje de veces que el valor de $F_{\theta}$ tiene un signo distinto a la moda es alto coincide con las regiones donde se encuentra el río. 


```{r L-espacial, fig.cap="Porcentaje de veces que el valor local de L (a) y el flujo vertical de calor (b) tiene signo distinto a la moda del dominio calculada en todo el periodo analizado. Se muestran los valores mayores al 5\\% (colores) y topografía del dominio (contornos). Datos de la simulación YSU. \\label{L-esp}", fig.width=0.95*text.width, fig.align='center'}

hgt <- ReadNetCDF(paste(path, "caso1_YSU/hgt_YSU.nc", sep = "")) %>% 
  .[date == "2016-01-14 21:00:00 UTC" & lev == 0.05, ]

L.YSU <- ReadNetCDF(paste(path,"caso1_YSU/l_YSU.nc", sep = "")) %>% 
  .[, param := "YSU"] %>% 
  .[, lev := lev*1000 -75] %>% 
  .[, L := l[1], by = .(date, lon, lat, param)] %>% 
  .[date %between% as.POSIXct(c("2016-01-13 22:00:00", "2016-01-14 22:00:00"), tz = "UTC"), ] %>% 
  .[inside(lon, lat) == T, ]

L <- copy(L.YSU)[, La := L*mode(L), by = .(date)] %>% 
  .[, .(mean = mean(La < 0)), by = .(lon, lat)] %>% 
  .[mean > 0.05, ] %>% 
  .[, var := "L"]

hfx.YSU <- ReadNetCDF(paste(path,"caso1_YSU/hfx_YSU.nc", sep = "")) %>% 
  .[, param := "YSU"] %>% 
  .[, lev := lev*1000 -75] %>% 
  .[, hfx := hfx[1], by = .(date, lon, lat, param)] %>% 
  .[date %between% as.POSIXct(c("2016-01-13 22:00:00", "2016-01-14 22:00:00"), tz = "UTC"), ] %>% 
  .[inside(lon, lat) == T, ]

hfx <- hfx.YSU[lev == -25, hfxa := hfx*mode(hfx), by = .(date)] %>% 
  .[lev == -25, .(mean = mean(hfxa < 0)), by = .(lon, lat)] %>% 
  .[mean > 0.05, ] %>% 
  .[, var := "hfx"]

rbind(L, hfx) %>% 
  .[, var := factor(var, levels = c("L", "hfx"), labels = c("L", "F[theta]"))] %>% 
  ggplot(aes(lon, lat)) +
  geom_tile(aes(fill = mean*100)) +
  geom_contour(data = hgt, aes(z = hgt), 
               color = "darkgrey") +
  scale_fill_viridis(name = "", guide = guide_colorbar(title.position = "top", 
                                              title.hjust = 0.5),
                     direction = -1) +
  scale_x_continuous(name = "Longitud", expand = c(0,0)) +
  scale_y_continuous(name = "Latitud", expand = c(0,0)) +
  annotate(geom = "point", x = -60.537289, y = -31.848438, size = 2) +
  coord_quickmap() + 
  facet_wrap(~var, 
             labeller = label_parsed) +
  theme_minimal() + theme(legend.position = "bottom")

remove(hfx, hfx.YSU, L, L.YSU)

```
Entonces nos quedamos con el análsis en un punto cercano al radar que además no presenta gran variabilidad respecto de la región circundante.



```{r leo-pbl}

caso.YSU <- ReadNetCDF(paste(path,"caso1_YSU/spd_YSU.nc", sep = "")) %>% 
  mutate(exchh = ReadNetCDF(paste(path,"caso1_YSU/exchh_YSU.nc", sep = ""), out = "vector")[[1]],
         pblh = ReadNetCDF(paste(path,"caso1_YSU/pblh_YSU.nc", sep = ""), out = "vector")[[1]],
         ust = ReadNetCDF(paste(path,"caso1_YSU/ust_YSU.nc", sep = ""), out = "vector")[[1]],
         L = ReadNetCDF(paste(path,"caso1_YSU/l_YSU.nc", sep = ""), out = "vector")[[1]],
         param = "YSU") %>% 
  .[, lev := lev*1000 - 75] %>% 
  .[, c("pblh", "ust", "L") := .(pblh[1], ust[1], L[1]), by = .(date, lon, lat, param)] %>% 
  .[, regimen := ifelse(L <= 0, "Inestable", "Estable")] %>% 
  .[date %between% as.POSIXct(c("2016-01-13 22:10:00", "2016-01-14 22:00:00"), tz = "UTC"), ] %>% 
  .[inside(lon, lat) == T] %>% 
  .[lev > -25,]

caso.MYJ <- ReadNetCDF(paste(path,"caso1_MYJ/spd_MYJ.nc", sep = "")) %>% 
  mutate(exchh = ReadNetCDF(paste(path,"caso1_MYJ/exchh_MYJ.nc", sep = ""), out = "vector")[[1]],
         pblh = ReadNetCDF(paste(path,"caso1_MYJ/pblh_MYJ.nc", sep = ""), out = "vector")[[1]],
         ust = ReadNetCDF(paste(path,"caso1_MYJ/ust_MYJ.nc", sep = ""), out = "vector")[[1]],
         L = ReadNetCDF(paste(path,"caso1_MYJ/l_MYJ.nc", sep = ""), out = "vector")[[1]],
         param = "MYJ") %>% 
  .[, lev := lev*1000 - 75] %>% 
  .[, c("pblh", "ust", "L") := .(pblh[1], ust[1], L[1]), by = .(date, lon, lat, param)] %>% 
  .[, regimen := ifelse(L <= 0, "Inestable", "Estable")] %>% 
  .[date %between% as.POSIXct(c("2016-01-13 22:10:00", "2016-01-14 22:00:00"), tz = "UTC"), ] %>% 
  .[inside(lon, lat) == T] %>% 
  .[lev > -25,]

caso.ACM2 <- ReadNetCDF(paste(path,"caso1_ACM2/spd_ACM2.nc", sep = "")) %>% 
  mutate(exchh = ReadNetCDF(paste(path,"caso1_ACM2/exchh_ACM2.nc", sep = ""), out = "vector")[[1]],
         pblh = ReadNetCDF(paste(path,"caso1_ACM2/pblh_ACM2.nc", sep = ""), out = "vector")[[1]],
         ust = ReadNetCDF(paste(path,"caso1_ACM2/ust_ACM2.nc", sep = ""), out = "vector")[[1]],
         L = ReadNetCDF(paste(path,"caso1_YSU/l_YSU.nc", sep = ""), out = "vector")[[1]],
         param = "ACM2") %>% 
  .[, lev := lev*1000 - 75] %>% 
  .[, c("pblh", "ust", "L") := .(pblh[1], ust[1], L[1]), by = .(date, lon, lat, param)] %>% 
  .[, regimen := ifelse(L <= 0, "Inestable", "Estable")] %>% 
  .[date %between% as.POSIXct(c("2016-01-13 22:10:00", "2016-01-14 22:00:00"), tz = "UTC"), ] %>% 
  .[inside(lon, lat) == T] %>% 
  .[lev > -25,]

all.pbl <- rbind(caso.YSU, caso.MYJ, caso.ACM2) %>% 
  .[lat %~% -31.8484 & lon %~% -60.5372] %>% 
  .[, param :=  factor(param,
                       levels = c("YSU", "MYJ", "ACM2"),
                       ordered = T)]

remove(list = c("caso.YSU", "caso.MYJ", "caso.ACM2"))
```

```{r L-parm, fig.cap="Longitud de Monin Obukhov (m) en función del tiempo, para cada simulación. \\label{L-param}", fig.width=0.95*text.width, fig.align='center'}

ggplot(all.pbl, aes(date, L)) +
  geom_point(aes(color = regimen)) +
  geom_hline(yintercept = 0, color = "darkgrey") +
  scale_color_manual(name = "Regimen", values = color_manual) +
  scale_y_continuous(name = "L (m)", breaks = seq(-400, 300, 50)) +
  scale_x_datetime(name = "Hora (UTC)", 
                   date_breaks = "6 hours", 
                   date_labels = "%H") +
  facet_wrap(~param) +
  theme_minimal() 

```


#### Altura de la capa límite


```{r pblh-wrf, fig.cap="Altura de la capa límite en cada silumación. \\label{pblh-wrf}", fig.subcap=c("Estimada directamente por cada esquema de CLP. \\label{pblh}", "Comparación entre la altura calculada por cada esquema y la estimada a partir de la altura del viento máximo (sólo período estable). \\label{pblh-spd}"), fig.width=0.48*text.width, fig.align='center', fig.sep = "\\hfill"}

all.pbl[lev < 30] %>%
  ggplot(aes(date, pblh)) +
  geom_vline(xintercept = as_datetime("2016-01-14 09:40:00"), 
             color = "darkgray") +
  geom_line(aes(color = param), linetype = 1) +
  scale_color_viridis(name = "Simulación", discrete = T, option = "viridis") +
  scale_y_continuous(name = "Altura de la capa límite (m)", limits = c(0, 4000)) +
  scale_x_datetime(name = "Hora UTC",
                   date_breaks = "4 hours", 
                   date_labels = "%H") +
  theme_minimal() 

all.pbl[lev < 2500 & L >=0 , .(pblh = pblh[1], pblh.spd = lev[which.max(spd)], L = L[1]), by = .(date, param)] %>%   .[!is.na(pblh), ] %>% 
  ggplot(aes(pblh, pblh.spd)) +
  geom_abline(slope = 1, intercept = 0) +
  geom_point(aes(color = param)) +
  scale_color_viridis(name = "Simulación", discrete = T) +
  scale_x_continuous(name = "h") +
  scale_y_continuous(name = expression(h[máx])) +
  theme_minimal()
```

```{r}
a <- all.pbl[lev < 2500 & L >=0 , .(pblh = pblh[1], pblh.spd = lev[which.max(spd)], L = L[1]), by = .(date, param)] %>%   .[!is.na(pblh), ] 

group_by(a, param) %>% 
  summarise(cor = cor(pblh, pblh.spd)) %>% 
  kable(digits = 4)
  
```


Comparación entre simulaciones y observaciones
Gráfico de dispersión para analizar la altura obtenida con umax

#### Coeficientes de difusividad turbulenta

```{r make-ulke}
all.pbl <- all.pbl[, c("kh.u", "km.u", "u.u") := .(
  kh.ulke(lev, pblh, L, ust),
  km.ulke(lev, pblh, L, ust),
  u.ulke(lev, pblh, L, ust))] %>% 
  .[, Pr := km.u/kh.u]
```

Coeficiente de difusividad de calor que sale del WRF


```{r kh_wrf, fig.cap="BORRADOR - Coeficiente de difusividad de calor $K_h$ ($m^2/s$) promediado para todo el período estable (izquierda) y el período inestable (derecha) de la capa límite en todas las simulaciones. \\label{kh_wrf}", fig.align='center', fig.width=0.95*text.width}

group_by(all.pbl, param, lev, regimen) %>% 
  summarise(Kh = mean(exchh, na.rm = T)) %>% 
  ungroup() %>% 
  ggplot(aes(lev, Kh)) + 
  geom_line(aes(color = as.factor(param))) +
  scale_color_viridis(name = "Metodología",discrete = T, option = "viridis") +
  scale_y_continuous(name = expression(paste(K[h], " (", m^2/s, ")"))) +
  scale_x_continuous(name = "Altura sobre el nivel del suelo (Km)", 
                     limits = c(0, 1500)) +
  facet_wrap(~regimen, scales = "free") +
  coord_flip() +
  theme_minimal()
```


```{r kh_ulke, fig.cap="BORRADOR - Coeficiente de difusividad de calor $K_h$ ($m^2/s$) promediado sobre el período estable (izquierda) y el período inestable (derecha) de la capa límite calculados a partir de los modelos propuestos por Ulke 2000 \\label{kh-ulke}", fig.align='center', fig.width=0.95*text.width}

group_by(all.pbl, param, lev, regimen) %>% 
  summarise(Kh.u = mean(kh.u, na.rm = T), Km.u = mean(km.u, na.rm = T)) %>% 
  ungroup() %>%
  .[, Pr := Km.u/Kh.u] %>%
  .[Kh.u > 0 & Km.u > 0, ] %>% 
  ggplot(aes(lev, Kh.u)) + 
  geom_line(aes(color = as.factor(param))) +
  scale_color_viridis(name = "Esquema",discrete = T, option = "viridis") +
  scale_y_continuous(name = expression(paste(K[h], " (", m^2/s, ")"))) +
  scale_x_continuous(name = "Altura sobre el nivel del suelo (Km)") +
  facet_wrap(~regimen, scales = "free") +
  #labs(title = "Perfiles a partir del promedio del dominio") +
  coord_flip() +
  theme_minimal()
```

```{r k_norm, fig.cap="Coeficiente de difusividad normalizados calculados a partir de los modelos propuestos por Ulke 2000 y promediados sobre en período estable (izquierda) y el período inestable (derecha) de la capa límite. \\label{kh-ulke}", fig.subcap=c("$K_h* = K_h/khu_*$ \\label{kh-norm}", "$K_m* = K_m/khu_*$ \\label{km-norm}"), fig.align='center', fig.height=0.40*text.height, fig.width=0.95*text.width, fig.ncol=1}

all.pbl_norm <- all.pbl[, `:=`(kh.u_norm = kh.u/(ust*0.4*pblh),
             km.u_norm = km.u/(ust*0.4*pblh), 
             lev_norm = lev/pblh), 
             by = .(param, regimen)] %>% 
  .[, .(lev_norm = seq(0, 1, by = 0.1),
        kh.u_norm = approx(lev_norm, kh.u_norm, xout = seq(0, 1, by = 0.1))$y,
        km.u_norm = approx(lev_norm, km.u_norm, xout = seq(0, 1, by = 0.1))$y), 
    by = .(param, regimen, date)] %>% 
  .[, lapply(.SD, mean, na.rm = T), by = .(param, lev_norm, regimen), .SDcols = -"date"]

ggplot(all.pbl_norm, aes(lev_norm, kh.u_norm)) + 
  geom_line(aes(color = as.factor(param))) +
  scale_color_viridis(name = "Esquema",discrete = T, option = "viridis") +
  scale_y_continuous(name = expression(paste(K[h], "*"))) +
  scale_x_continuous(name = "z/h") +
  facet_wrap(~regimen, scales = "free") +
  #labs(title = "Perfiles a partir del promedio del dominio") +
  coord_flip() +
  theme_minimal() 

ggplot(all.pbl_norm, aes(lev_norm, km.u_norm)) + 
  geom_line(aes(color = as.factor(param))) +
  scale_color_viridis(name = "Esquema",discrete = T, option = "viridis") +
  scale_y_continuous(name = expression(paste(K[m], "*"))) +
  scale_x_continuous(name = "z/h") +
  facet_wrap(~regimen, scales = "free") +
  #labs(title = "Perfiles a partir del promedio del dominio") +
  coord_flip() +
  theme_minimal()
```


```{r pr, fig.cap="Variación del número de Prandtl calculado a partir del modelo propuesto por Ulke 2000 con las variables de cada simulación y promediado en cada periodo. \\label{Pr}", fig.align='center', fig.width=0.95*text.width}
group_by(all.pbl, param, lev, regimen) %>%
  summarise(Pr = mean(Pr, na.rm = T)) %>%
ungroup() %>%
ggplot(aes(lev, Pr)) + 
  geom_line(aes(color = as.factor(param))) +
  scale_color_viridis(name = "Esquema",discrete = T, option = "viridis") +
  scale_y_continuous(name = "Km/Kh") +
  scale_x_continuous(name = "z", limits = c(0,1500)) +
  facet_wrap(~regimen, scales = "free") +
  #labs(title = "Perfiles a partir del promedio del dominio") +
  coord_flip() +
  theme_minimal()
```

```{r tabla-clp}
hL <- group_by(all.pbl, param, regimen) %>% 
  summarise(h_mean = mean(pblh, na.rm = T), 
            L_mean = mean(L, na.rm = T), 
            ust_mean = mean(ust, na.rm = T),
            Pr_mean =  mean(Pr, na.rm = T)) %>% 
  .[, hL := h_mean/L_mean]

names(hL) <-  c("Simulación", "Regimen", "$\\overline{h}$", "$\\overline{L}$", "$\\overline{u*}$", "$\\overline{Pr}$", "$h/L$")

names(hL)[3] <- paste0(names(hL)[3], footnote_marker_number(1, "latex"))
names(hL)[4] <- paste0(names(hL)[4], footnote_marker_number(2, "latex"))
names(hL)[5] <- paste0(names(hL)[5], footnote_marker_number(3, "latex"))
names(hL)[6] <- paste0(names(hL)[6], footnote_marker_number(4, "latex"))

kable(hL, "latex",
      caption = "Parámetros característicos de la capa límite para cada simulación y regimen, promediados para todo el periodo y todo el perfil (en los casos que corresponda).", 
      escape = F,
      booktabs = T,
      digits = c(0,0,2,2,4,2,2)) %>% 
  kable_styling(full_width = F) %>% 
  footnote(general_title = "Nota",
           escape = F,
           number = c("Altura de la CLP promediada.",
                      "Longitud de Monin Obukhov promediada.",
                      "Velocidad de fricción promediada.",
                      "Número de Prandtl promediado."))


# col.names = c("Simulación", "Regimen", "$\\overline{h}$", "$\\overline{L}$", "$\\overline{u*}$", "$\\overline{Pr}$", "h/L")
```

```{r k_ulke_wrf, fig.cap="Coeficientes de difusividad promediados para todo el período estable (izquierda) y el período inestable (derecha) de la capa límite en todas las simulaciones. \\label{kh_wrf}", fig.subcap=c("Calor $K_h$ ($m^2/s$). \\label{kh-wrf}", "Moviento $K_m$ ($m^2/s$). \\label{km-wrf-ulke}"), fig.align='center', fig.width=0.98*text.width, fig.ncol=1, fig.height=0.40*text.height}

all.pbl <- all.pbl[, exchm := Pr*exchh]
d <- group_by(all.pbl, param, lev, regimen) %>% 
  summarise(Kh.m = mean(exchh, na.rm = T), Km.m = mean(exchm, na.rm = T)) %>% 
  ungroup()

ggplot(d, aes(lev, Kh.m)) + 
  geom_line(aes(color = as.factor(param))) +
  scale_color_viridis(name = "Esquema",discrete = T, option = "viridis") +
  scale_y_continuous(name = expression(paste(K[h], " (", m^2,s^{-1}, ")"))) +
  scale_x_continuous(name = "Altura sobre el nivel del suelo (Km)", limits = c(0, 1500)) +
  facet_wrap(~regimen, scales = "free") +
  #labs(title = "Perfiles a partir del promedio del dominio") +
  coord_flip() +
  theme_minimal() 

ggplot(d, aes(lev, Km.m)) + 
  geom_line(aes(color = as.factor(param))) +
  scale_color_viridis(name = "Esquema",discrete = T, option = "viridis") +
  scale_y_continuous(name = expression(paste(K[m], " (", m^2,s^{-1}, ")"))) +
  scale_x_continuous(name = "Altura sobre el nivel del suelo (Km)", limits = c(0, 1500)) +
  facet_wrap(~regimen, scales = "free") +
  #labs(title = "Perfiles a partir del promedio del dominio") +
  coord_flip() +
  theme_minimal() 
  
remove("d")
```

# Conclusiones

# Referencias